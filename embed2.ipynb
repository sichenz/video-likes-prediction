{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b91efd1a4404ca6a0da00f5dc88cc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing videos and extracting embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfa07d05c37496a9db0997abb71588c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding Videos:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to video_embeddings_new.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import av\n",
    "from transformers import VideoLlavaForConditionalGeneration, VideoLlavaProcessor\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    \"\"\"\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (av.container.input.InputContainer): PyAV container.\n",
    "        indices (List[int]): List of frame indices to decode.\n",
    "    Returns:\n",
    "        np.ndarray: Decoded frames of shape (num_frames, height, width, 3).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    if len(frames) < len(indices):\n",
    "        # Handle cases where the video has fewer frames than expected\n",
    "        last_frame = frames[-1]\n",
    "        while len(frames) < len(indices):\n",
    "            frames.append(last_frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "def extract_video_embedding(model, processor, video_path, device):\n",
    "    \"\"\"\n",
    "    Extract embedding for a single video.\n",
    "    Args:\n",
    "        model (VideoLlavaForConditionalGeneration): The Video-LLaVA model.\n",
    "        processor (VideoLlavaProcessor): The processor for Video-LLaVA.\n",
    "        video_path (str): Path to the video file.\n",
    "        device (torch.device): Device to run the model on.\n",
    "    Returns:\n",
    "        np.ndarray: Embedding vector for the video.\n",
    "    \"\"\"\n",
    "    container = av.open(video_path)\n",
    "    total_frames = container.streams.video[0].frames\n",
    "    if total_frames == 0:\n",
    "        raise ValueError(f\"No frames found in video: {video_path}\")\n",
    "    # Sample uniformly 8 frames\n",
    "    step = max(total_frames // 8, 1)\n",
    "    indices = list(range(0, min(total_frames, step * 8), step))[:8]\n",
    "    if len(indices) < 8:\n",
    "        # Pad with the last frame if not enough frames\n",
    "        indices += [indices[-1]] * (8 - len(indices))\n",
    "    video = read_video_pyav(container, indices)\n",
    "\n",
    "    # Prepare prompt (dummy prompt as we are extracting embeddings)\n",
    "    prompt = \"USER: <video>\\nExtract embedding. ASSISTANT:\"\n",
    "    inputs = processor(text=prompt, videos=video, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        # Extract video_hidden_states\n",
    "        video_hidden_states = outputs.video_hidden_states  # Shape: (batch_size, num_frames, hidden_size)\n",
    "        # Average across frames to get a single embedding vector\n",
    "        embedding = video_hidden_states.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return embedding\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize model and processor\n",
    "    model_name = \"LanguageBind/Video-LLaVA-7B-hf\"\n",
    "    model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\" if device.type == \"cuda\" else None\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    processor = VideoLlavaProcessor.from_pretrained(model_name)\n",
    "    # Set padding_side to \"left\" as per usage tips\n",
    "    processor.tokenizer.padding_side = \"left\"\n",
    "\n",
    "    # Directory containing videos\n",
    "    videos_dir = \"videos_new\"\n",
    "    if not os.path.isdir(videos_dir):\n",
    "        raise ValueError(f\"Directory '{videos_dir}' does not exist.\")\n",
    "\n",
    "    # Supported video extensions\n",
    "    video_extensions = {\".mp4\", \".mov\", \".avi\", \".mkv\"}\n",
    "\n",
    "    # List all video files\n",
    "    video_files = [\n",
    "        f for f in os.listdir(videos_dir)\n",
    "        if os.path.splitext(f)[1].lower() in video_extensions\n",
    "    ]\n",
    "\n",
    "    if not video_files:\n",
    "        raise ValueError(f\"No video files found in directory '{videos_dir}'.\")\n",
    "\n",
    "    # Prepare list to hold filename and embeddings\n",
    "    data = []\n",
    "\n",
    "    print(\"Processing videos and extracting embeddings...\")\n",
    "    for video_file in tqdm(video_files, desc=\"Embedding Videos\"):\n",
    "        video_path = os.path.join(videos_dir, video_file)\n",
    "        filename, _ = os.path.splitext(video_file)\n",
    "        try:\n",
    "            embedding = extract_video_embedding(model, processor, video_path, device)\n",
    "            # Convert embedding to list for CSV\n",
    "            embedding_list = embedding.tolist()\n",
    "            # Optionally, you can reduce the embedding size or process it further\n",
    "            data.append({\n",
    "                \"filename\": filename,\n",
    "                \"embedding\": embedding_list\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv = \"video_embeddings_new.csv\"\n",
    "    # To store embeddings as strings, join the list elements\n",
    "    df['embedding'] = df['embedding'].apply(lambda x: \",\".join(map(str, x)))\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Embeddings saved to {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video_embeddings_new.csv...\n",
      "Reading video_features_new.csv...\n",
      "Processing filenames to remove extensions...\n",
      "Merging DataFrames with merge type 'inner'...\n",
      "Saving merged data to video_info_new.csv...\n",
      "Merge completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "\n",
    "def merge_csv_files(embeddings_file, features_file, output_file, merge_type='inner'):\n",
    "    \"\"\"\n",
    "    Merges video_embeddings.csv with video_features.csv based on video filenames.\n",
    "\n",
    "    Args:\n",
    "        embeddings_file (str): Path to video_embeddings.csv.\n",
    "        features_file (str): Path to video_features.csv.\n",
    "        output_file (str): Path to save the merged video_info.csv.\n",
    "        merge_type (str): Type of merge to perform ('inner', 'outer', 'left', 'right').\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if input files exist\n",
    "    if not os.path.isfile(embeddings_file):\n",
    "        raise FileNotFoundError(f\"The file {embeddings_file} does not exist.\")\n",
    "    if not os.path.isfile(features_file):\n",
    "        raise FileNotFoundError(f\"The file {features_file} does not exist.\")\n",
    "\n",
    "    # Read video_embeddings.csv\n",
    "    print(f\"Reading {embeddings_file}...\")\n",
    "    embeddings_df = pd.read_csv(embeddings_file)\n",
    "\n",
    "    # Ensure necessary columns exist\n",
    "    if 'filename' not in embeddings_df.columns or 'embedding' not in embeddings_df.columns:\n",
    "        raise ValueError(f\"{embeddings_file} must contain 'filename' and 'embedding' columns.\")\n",
    "\n",
    "    # Convert 'filename' in embeddings_df to string\n",
    "    embeddings_df['filename'] = embeddings_df['filename'].astype(str)\n",
    "\n",
    "    # Read video_features.csv\n",
    "    print(f\"Reading {features_file}...\")\n",
    "    features_df = pd.read_csv(features_file)\n",
    "\n",
    "    # Ensure 'filename' column exists\n",
    "    if 'filename' not in features_df.columns:\n",
    "        raise ValueError(f\"{features_file} must contain a 'filename' column.\")\n",
    "\n",
    "    # Extract filename without extension from features_df\n",
    "    print(\"Processing filenames to remove extensions...\")\n",
    "    features_df['filename_no_ext'] = features_df['filename'].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "    # Convert 'filename_no_ext' to string\n",
    "    features_df['filename_no_ext'] = features_df['filename_no_ext'].astype(str)\n",
    "\n",
    "    # Merge the two DataFrames on 'filename_no_ext' and 'filename'\n",
    "    print(f\"Merging DataFrames with merge type '{merge_type}'...\")\n",
    "    merged_df = pd.merge(\n",
    "        features_df,\n",
    "        embeddings_df,\n",
    "        left_on='filename_no_ext',\n",
    "        right_on='filename',\n",
    "        how=merge_type\n",
    "    )\n",
    "\n",
    "    # Drop redundant columns\n",
    "    # After merging, 'filename_x' comes from features_df and 'filename_y' from embeddings_df\n",
    "    columns_to_drop = ['filename_no_ext', 'filename_y']\n",
    "    merged_df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Rename 'filename_x' to 'filename'\n",
    "    merged_df.rename(columns={'filename_x': 'filename'}, inplace=True)\n",
    "\n",
    "    # Optional: Reorder columns to place 'embedding' at the end\n",
    "    cols = [col for col in merged_df.columns if col != 'embedding'] + ['embedding']\n",
    "    merged_df = merged_df[cols]\n",
    "\n",
    "    # Save the merged DataFrame to CSV\n",
    "    print(f\"Saving merged data to {output_file}...\")\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"Merge completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file paths\n",
    "    embeddings_csv = 'video_embeddings_new.csv'  # Path to your video_embeddings.csv\n",
    "    features_csv = 'video_features_new.csv'      # Path to your video_features.csv\n",
    "    output_csv = 'video_info_new.csv'            # Desired output file\n",
    "\n",
    "    # Define merge type: 'inner', 'outer', 'left', 'right'\n",
    "    # 'inner' will only include rows with matching filenames in both CSVs\n",
    "    # 'outer' will include all rows, filling NaN where there are no matches\n",
    "    merge_type = 'inner'  # Change to 'outer' if you want all records\n",
    "\n",
    "    # Call the merge function\n",
    "    merge_csv_files(embeddings_csv, features_csv, output_csv, merge_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
