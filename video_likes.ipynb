{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory: /home/sz4972/.cache/huggingface/hub\n",
      "Size before clearing:\n",
      "29G\t/home/sz4972/.cache/huggingface/hub\n",
      "Removed /home/sz4972/.cache/huggingface/hub/models--openai--clip-vit-large-patch14-336\n",
      "Removed /home/sz4972/.cache/huggingface/hub/.locks\n",
      "Removed /home/sz4972/.cache/huggingface/hub/models--xtuner--llava-phi-3-mini-hf\n",
      "Removed /home/sz4972/.cache/huggingface/hub/models--ICTNLP--llava-mini-llama-3.1-8b\n",
      "\n",
      "Size after clearing:\n",
      "512\t/home/sz4972/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from huggingface_hub import constants\n",
    "\n",
    "# Get the cache directory\n",
    "cache_dir = constants.HF_HUB_CACHE\n",
    "print(f\"Cache directory: {cache_dir}\")\n",
    "\n",
    "# Check size before deletion\n",
    "print(\"Size before clearing:\")\n",
    "!du -sh {cache_dir}\n",
    "\n",
    "# Clear the cache manually\n",
    "if os.path.exists(cache_dir):\n",
    "    for item in os.listdir(cache_dir):\n",
    "        item_path = os.path.join(cache_dir, item)\n",
    "        try:\n",
    "            if os.path.isfile(item_path):\n",
    "                os.unlink(item_path)\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "            print(f\"Removed {item_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {item_path}: {e}\")\n",
    "    \n",
    "    print(\"\\nSize after clearing:\")\n",
    "    !du -sh {cache_dir}\n",
    "else:\n",
    "    print(f\"Cache directory {cache_dir} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 84\n",
      "Cleared /home/sz4972/.cache/pip\n"
     ]
    }
   ],
   "source": [
    "# Clear pip cache\n",
    "!pip cache purge\n",
    "\n",
    "# Clear Jupyter cache\n",
    "jupyter_cache = os.path.expanduser(\"~/.jupyter/cache\")\n",
    "if os.path.exists(jupyter_cache):\n",
    "    shutil.rmtree(jupyter_cache)\n",
    "    print(f\"Cleared Jupyter cache: {jupyter_cache}\")\n",
    "\n",
    "# Clear Python cache files\n",
    "!find ~ -name \"__pycache__\" -type d -exec rm -rf {} + 2>/dev/null || true\n",
    "!find ~ -name \"*.pyc\" -delete\n",
    "\n",
    "# Clear other common caches\n",
    "for cache_dir in [\n",
    "    \"~/.cache/pip\",\n",
    "    \"~/.cache/torch\",\n",
    "    \"~/.cache/tensorflow\",\n",
    "    \"~/.cache/models\"\n",
    "]:\n",
    "    expanded_dir = os.path.expanduser(cache_dir)\n",
    "    if os.path.exists(expanded_dir):\n",
    "        try:\n",
    "            shutil.rmtree(expanded_dir)\n",
    "            print(f\"Cleared {expanded_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error clearing {expanded_dir}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izOhUORNEHMI",
    "outputId": "e2f66c62-cb86-4c0e-9c84-13a92e40b8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (1.24.4)\n",
      "Requirement already satisfied: av in ./.local/lib/python3.9/site-packages (14.2.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.9/site-packages (4.49.0)\n",
      "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.9/site-packages (0.29.3)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.9/site-packages (4.62.3)\n",
      "Requirement already satisfied: pandas in /ext3/miniconda3/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: librosa in ./.local/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.9/site-packages (6.30.1)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /ext3/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /ext3/miniconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.9/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./.local/lib/python3.9/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.local/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.local/lib/python3.9/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.local/lib/python3.9/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.local/lib/python3.9/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.local/lib/python3.9/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.local/lib/python3.9/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: click in /ext3/miniconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.local/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /ext3/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /ext3/miniconda3/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /ext3/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /ext3/miniconda3/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: pycparser in /ext3/miniconda3/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./.local/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: psutil in /ext3/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.local/lib/python3.9/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.local/lib/python3.9/site-packages (from accelerate>=0.26.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (21.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.local/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.29.3)\n",
      "Requirement already satisfied: pyyaml in /ext3/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: requests in /ext3/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /ext3/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.62.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /ext3/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate>=0.26.0) (3.0.7)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.0.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydub in ./.local/lib/python3.9/site-packages (0.25.1)\n",
      "Requirement already satisfied: librosa in ./.local/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in ./.local/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: pandas in /ext3/miniconda3/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.9/site-packages (4.62.3)\n",
      "Requirement already satisfied: fastapi in ./.local/lib/python3.9/site-packages (0.115.11)\n",
      "Requirement already satisfied: uvicorn in ./.local/lib/python3.9/site-packages (0.34.0)\n",
      "Requirement already satisfied: decord in ./.local/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.local/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.9/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.local/lib/python3.9/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.local/lib/python3.9/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: numpy>=1.22.3 in ./.local/lib/python3.9/site-packages (from librosa) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./.local/lib/python3.9/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.local/lib/python3.9/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.local/lib/python3.9/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /ext3/miniconda3/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./.local/lib/python3.9/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /ext3/miniconda3/lib/python3.9/site-packages (from soundfile) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /ext3/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /ext3/miniconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./.local/lib/python3.9/site-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.local/lib/python3.9/site-packages (from fastapi) (0.46.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.local/lib/python3.9/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /ext3/miniconda3/lib/python3.9/site-packages (from uvicorn) (8.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /ext3/miniconda3/lib/python3.9/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pycparser in /ext3/miniconda3/lib/python3.9/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: packaging in /ext3/miniconda3/lib/python3.9/site-packages (from lazy_loader>=0.1->librosa) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /ext3/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /ext3/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /ext3/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /ext3/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.29.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.local/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /ext3/miniconda3/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.27.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /ext3/miniconda3/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /ext3/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.local/lib/python3.9/site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /ext3/miniconda3/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /ext3/miniconda3/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy av transformers huggingface_hub tqdm pandas librosa nltk protobuf sentencepiece opencv-python\n",
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip install pydub librosa soundfile pandas tqdm fastapi uvicorn decord seaborn xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjiiDg4TEHMK"
   },
   "source": [
    "### 在运行此笔记本之前，请将变量 **VIDEO_FOLDER** 更改为您的视频文件夹名称，并将 **VIDEO_SHEET_CSV** 更改为您的 CSV 表，该表有每个视频 ID 到其对应的点赞数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shdO-1sOEHMK"
   },
   "source": [
    "### Video Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg5pzsStEHMK",
    "outputId": "020eecc5-6e9a-4047-8fcc-153b90121c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffprobe is found in PATH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata with ffprobe: 100%|██████████| 13/13 [00:01<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 'id' values:\n",
      "0    269\n",
      "1    288\n",
      "2    276\n",
      "3    283\n",
      "4    268\n",
      "Name: id, dtype: int64\n",
      "Metadata extraction and merging complete. Metadata saved to 'video_features_new.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the paths to the video folder and CSV files\n",
    "VIDEO_FOLDER = 'videos_new' #change name to your own video folder\n",
    "OUTPUT_CSV = 'video_features_new.csv'\n",
    "VIDEO_SHEET_CSV = 'video_sheet.csv'  #change name to your .csv sheet with video likes info\n",
    "\n",
    "def get_ffprobe_metadata(video_path):\n",
    "    \"\"\"\n",
    "    Extracts metadata from a video file using ffprobe.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing video metadata.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    try:\n",
    "        # Construct ffprobe command\n",
    "        cmd = [\n",
    "            'ffprobe',\n",
    "            '-v', 'error',\n",
    "            '-print_format', 'json',\n",
    "            '-show_format',\n",
    "            '-show_streams',\n",
    "            video_path\n",
    "        ]\n",
    "\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Parse the JSON output\n",
    "        ffprobe_output = json.loads(result.stdout)\n",
    "\n",
    "        # Extract general format info\n",
    "        format_info = ffprobe_output.get('format', {})\n",
    "        metadata['filename'] = os.path.basename(video_path)\n",
    "        metadata['duration_seconds'] = float(format_info.get('duration', 0))\n",
    "        metadata['file_size_MB'] = float(format_info.get('size', 0)) / (1024 * 1024)\n",
    "\n",
    "        # Initialize fields\n",
    "        metadata['fps'] = None\n",
    "        metadata['width'] = None\n",
    "        metadata['height'] = None\n",
    "        metadata['codec'] = None\n",
    "        metadata['has_audio'] = False\n",
    "        metadata['audio_fps'] = None\n",
    "        metadata['audio_channels'] = None\n",
    "        metadata['num_frames'] = 0\n",
    "\n",
    "        # Iterate over streams\n",
    "        streams = ffprobe_output.get('streams', [])\n",
    "        for stream in streams:\n",
    "            if stream.get('codec_type') == 'video':\n",
    "                metadata['codec'] = stream.get('codec_name', 'Unknown')\n",
    "                metadata['width'] = stream.get('width', 0)\n",
    "                metadata['height'] = stream.get('height', 0)\n",
    "                # Calculate fps\n",
    "                r_frame_rate = stream.get('r_frame_rate', '0/0')\n",
    "                nums = r_frame_rate.split('/')\n",
    "                if len(nums) == 2 and int(nums[1]) != 0:\n",
    "                    metadata['fps'] = float(nums[0]) / float(nums[1])\n",
    "                # Number of frames\n",
    "                if 'nb_frames' in stream:\n",
    "                    metadata['num_frames'] = int(stream['nb_frames'])\n",
    "            elif stream.get('codec_type') == 'audio':\n",
    "                metadata['has_audio'] = True\n",
    "                metadata['audio_fps'] = float(stream.get('sample_rate', 0))\n",
    "                metadata['audio_channels'] = int(stream.get('channels', 0))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_path}: {e}\")\n",
    "        metadata = {\n",
    "            'filename': os.path.basename(video_path),\n",
    "            'duration_seconds': None,\n",
    "            'fps': None,\n",
    "            'width': None,\n",
    "            'height': None,\n",
    "            'num_frames': None,\n",
    "            'file_size_MB': None,\n",
    "            'codec': None,\n",
    "            'has_audio': None,\n",
    "            'audio_fps': None,\n",
    "            'audio_channels': None\n",
    "        }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def merge_video_metadata(df_metadata, info_csv):\n",
    "    \"\"\"\n",
    "    Merges the extracted metadata with additional video information.\n",
    "\n",
    "    Args:\n",
    "        df_metadata (pd.DataFrame): DataFrame containing video metadata.\n",
    "        info_csv (str): Path to 'video_info.csv'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame.\n",
    "    \"\"\"\n",
    "    # Extract 'id' by removing the extension and converting to integer\n",
    "    try:\n",
    "        df_metadata['id'] = df_metadata['filename'].apply(lambda x: int(os.path.splitext(x)[0]))\n",
    "    except ValueError as ve:\n",
    "        print(\"Error extracting 'id' from filenames. Ensure all filenames before '.mp4' are integers.\")\n",
    "        print(ve)\n",
    "        # Optionally, handle or remove problematic rows\n",
    "        raise\n",
    "\n",
    "    # Debugging: Print some IDs to verify\n",
    "    print(\"Sample 'id' values:\")\n",
    "    print(df_metadata['id'].head())\n",
    "\n",
    "    # Drop existing 'title', 'publish_time', 'likes' columns if present\n",
    "    columns_to_drop = ['title', 'publish_time', 'likes']\n",
    "    df_metadata = df_metadata.drop(columns=[col for col in columns_to_drop if col in df_metadata.columns])\n",
    "\n",
    "    # Read the additional video info CSV\n",
    "    try:\n",
    "        df_info = pd.read_csv(info_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{info_csv}' does not exist.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame or handle as needed\n",
    "\n",
    "    # Rename relevant columns for clarity and consistency\n",
    "    df_info = df_info.rename(columns={\n",
    "        '序号': 'id',\n",
    "        '标题': 'title',\n",
    "        '发布时间': 'publish_time',\n",
    "        '点赞数': 'likes'\n",
    "    })\n",
    "\n",
    "    # Ensure 'id' in df_info is of integer type\n",
    "    df_info['id'] = df_info['id'].astype(int)\n",
    "\n",
    "    # Merge the DataFrames on 'id'\n",
    "    merged_df = pd.merge(\n",
    "        df_metadata,\n",
    "        df_info[['id', 'title', 'publish_time', 'likes']],\n",
    "        on='id',\n",
    "        how='left'  # Use left join to retain all metadata entries\n",
    "    )\n",
    "\n",
    "    # Check for any missing merges\n",
    "    missing_info = merged_df[merged_df['title'].isnull()]\n",
    "    if not missing_info.empty:\n",
    "        print(\"Warning: The following video IDs did not have matching entries in 'video_info.csv':\")\n",
    "        print(missing_info['id'].tolist())\n",
    "\n",
    "    # Drop the temporary 'id' column as it's no longer needed\n",
    "    merged_df = merged_df.drop(columns=['id'])\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def main():\n",
    "    # Verify that ffprobe is accessible\n",
    "    from shutil import which\n",
    "    if which('ffprobe') is None:\n",
    "        print(\"Error: ffprobe is not installed or not found in PATH.\")\n",
    "        print(\"Please install ffmpeg (which includes ffprobe) and ensure it's accessible from the command line.\")\n",
    "        print(\"Refer to the installation instructions provided earlier.\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"ffprobe is found in PATH.\")\n",
    "\n",
    "    # Get list of video files\n",
    "    try:\n",
    "        video_files = [f for f in os.listdir(VIDEO_FOLDER) if f.lower().endswith('.mp4')]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The directory '{VIDEO_FOLDER}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    if not video_files:\n",
    "        print(f\"No '.mp4' files found in the directory '{VIDEO_FOLDER}'.\")\n",
    "        return\n",
    "\n",
    "    video_paths = [os.path.join(VIDEO_FOLDER, f) for f in video_files]\n",
    "\n",
    "    # Initialize a list to store metadata dictionaries\n",
    "    metadata_list = []\n",
    "\n",
    "    # Iterate over each video and extract metadata\n",
    "    for video_path in tqdm(video_paths, desc=\"Extracting metadata with ffprobe\"):\n",
    "        metadata = get_ffprobe_metadata(video_path)\n",
    "        metadata_list.append(metadata)\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df_metadata = pd.DataFrame(metadata_list)\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    columns_order = [\n",
    "        'filename',\n",
    "        'duration_seconds',\n",
    "        'fps',\n",
    "        'width',\n",
    "        'height',\n",
    "        'num_frames',\n",
    "        'file_size_MB',\n",
    "        'codec',\n",
    "        'has_audio',\n",
    "        'audio_fps',\n",
    "        'audio_channels'\n",
    "    ]\n",
    "\n",
    "    # Ensure all columns are present before reordering\n",
    "    df_metadata = df_metadata.reindex(columns=columns_order)\n",
    "\n",
    "    # Check if the additional CSV file exists\n",
    "    if not os.path.exists(VIDEO_SHEET_CSV):\n",
    "        print(f\"Error: The file '{VIDEO_SHEET_CSV}' does not exist.\")\n",
    "        print(\"Please ensure the additional CSV file is present in the working directory.\")\n",
    "        return\n",
    "\n",
    "    # Perform the merge\n",
    "    try:\n",
    "        merged_df = merge_video_metadata(df_metadata, VIDEO_SHEET_CSV)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during merging: {e}\")\n",
    "        return\n",
    "\n",
    "    if merged_df.empty:\n",
    "        print(\"Merged DataFrame is empty. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Reorder columns to include the new fields\n",
    "    final_columns_order = [\n",
    "        'filename',\n",
    "        'duration_seconds',\n",
    "        'fps',\n",
    "        'width',\n",
    "        'height',\n",
    "        'num_frames',\n",
    "        'file_size_MB',\n",
    "        'codec',\n",
    "        'has_audio',\n",
    "        'audio_fps',\n",
    "        'audio_channels',\n",
    "        'title',\n",
    "        'publish_time',\n",
    "        'likes'\n",
    "    ]\n",
    "\n",
    "    # Ensure all final columns are present\n",
    "    missing_final_cols = [col for col in final_columns_order if col not in merged_df.columns]\n",
    "    if missing_final_cols:\n",
    "        print(f\"Warning: The following expected columns are missing in the merged DataFrame: {missing_final_cols}\")\n",
    "        # Optionally, handle missing columns, e.g., fill with NaN\n",
    "        for col in missing_final_cols:\n",
    "            merged_df[col] = pd.NA\n",
    "\n",
    "    merged_df = merged_df[final_columns_order]\n",
    "\n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    merged_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Metadata extraction and merging complete. Metadata saved to '{OUTPUT_CSV}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek0jk5SnEHMM"
   },
   "source": [
    "### Video Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372,
     "referenced_widgets": [
      "87aac3331be4455ba33267e3a2d7d435",
      "df3e30c9ff7f4fdab6f06f954b115165",
      "c9b9903af3f24a9bb06cc89306308119",
      "c5cc0dd3cdae4c3f9656befac5464830",
      "9634df0b9a734cbc9dad40f8d0d95cad",
      "419fa0b3fd494c5391444d964b84f0ba",
      "d6de83563fdf44fe92c75b18f46f44e3",
      "a4654f6aac164f379911b35b818b3a8a",
      "39fc286c0ee444efac547d4715fab3e9",
      "0d12f1f605bc4fb697a628c4ffde836e",
      "34b9f0efa8184ab78f307019dcbe6c65",
      "e1dd6d5e784344beb94c047331db6ee7",
      "e4ead2c5b9b745e6bb76b127f50f5953",
      "ecc8b09352e04118ae193eb28af78879",
      "a67a5fe937204b5b8f5bd01e7cdb2256",
      "e687daddd2f0487ba92878a7281e5ba9",
      "fadbc59282cf4fac9e591abff4cba4e9",
      "62f57902c5a34c8ba9df3a17ec04088a",
      "649644b1e40743beaadd4b118c5e0da2",
      "161e89d5e12940b8b2578f982f938167",
      "f992c760007c4a64848e8c38e374c897",
      "b99d04e19fbe43ac94b8aaa3087b6a39",
      "2aee8f66b1514a829c5a4848c8e9ed93",
      "8b3f86b7f61441d69afe6227c4370740",
      "6d97656ec6ef4605ac2b1d3dc8b2efaa",
      "6b7b2cdf8c354eaeaeca3719bde42a55",
      "e043131b7a8c43a2999649dedf859c73",
      "c21f27bb523e49c0a5784d80b8c51600",
      "f43ec6daa1a84b18b65084d6f0cee304",
      "82ae457232e6499ab4fae65d0efb0666",
      "21f19fc25039400baa9a591b038e4695",
      "0b9791b6f59b454f8d587bf35441a4f3",
      "f2bb0affafb948c4aa9e05653f7b9376",
      "96ee96d16a754737bc548ca957f057d6",
      "3ac4618bd2f1482baba2e5dbac28be9a",
      "7aeb04b600c34772b1c4022cf21ffcfb",
      "6bec2f0f8aaa46739e85f7aebcda5ba4",
      "cd01c3096121408588c4d0af726a68b7",
      "afbf5643731c4372a0e5d0f66687be63",
      "5eaf7c6a4b524f438093b07d2855dff0",
      "e620713c095d4a1996bc37d20579f7d5",
      "d78a394e68f043f98f96976a288214eb",
      "562c55cfaacf4ba1a12bc8faad7a8d69",
      "f314d6e524a248dfae72e7512f7dbebc",
      "d1cf7743138143be841ea971c13705b7",
      "5653c8e6fc484d31a9c9e920106d8f63",
      "78b0f5ae4d2b4284b530a5d8df3a792a",
      "2fabf13660a44f8fa186c8cd01b97663",
      "42292df633dd4c7cb00e03fcfe0f0623",
      "53eb04f5383c4369a7eb67d43045d84c",
      "68f63f216c4148908ff01ec951f32ac6",
      "2796f08190dd4f1bb57a5514e30165be",
      "b1f3f90c894245268c4668f747fa8cd3",
      "0b0120ee620a47978946e3256b7b1a32",
      "cbcf3f0dbe434f1ebd6d41f7a7010df5"
     ]
    },
    "id": "5L5tHmM0EHMM",
    "outputId": "e8d0b8b3-83dc-466f-dbc4-7566ccddfc9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:48:42,793 - INFO - Using device: cpu\n",
      "2025-03-19 06:48:42,793 - INFO - Loading model: xtuner/llava-phi-3-mini-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345f2e3d0d674adc93f9a96fea6806e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d227e2fd5bbe428aa85ec33edf036b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66fef5abb6f430e85a7e99d4f01e34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf4c1c7d8ff4bb8b0709f1c7fbb7e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ecd1a8c864473f97a5f0e6e105a765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10d31b62868426b8851d80c3924bb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7579c01515e5427d955533450bb29a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/140 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:49:36,204 - INFO - Model keys: ['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_assisted_decoding', '_auto_class', '_autoset_attn_implementation', '_backward_compatibility_gradient_checkpointing', '_backward_hooks', '_backward_pre_hooks', '_beam_search', '_buffers', '_call_impl', '_check_and_enable_flash_attn_2', '_check_and_enable_flex_attn', '_check_and_enable_sdpa', '_compiled_call_impl', '_constrained_beam_search', '_contrastive_search', '_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_create_repo', '_dispatch_accelerate_model', '_dola_decoding', '_expand_inputs_for_generation', '_fix_state_dict_key_on_load', '_fix_state_dict_key_on_save', '_fix_state_dict_keys_on_load', '_fix_state_dict_keys_on_save', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_from_config', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_cache', '_get_candidate_generator', '_get_files_timestamps', '_get_initial_cache_position', '_get_logits_processor', '_get_name', '_get_no_split_modules', '_get_resized_embeddings', '_get_resized_lm_head', '_get_stopping_criteria', '_group_beam_search', '_has_unfinished_sequences', '_hf_peft_config_loaded', '_hook_rss_memory_post_forward', '_hook_rss_memory_pre_forward', '_init_added_embeddings_weights_with_mean', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', '_init_weights', '_initialize_weights', '_is_full_backward_hook', '_is_hf_initialized', '_is_stateful', '_keep_in_fp32_modules', '_keep_in_fp32_modules', '_keys_to_ignore_on_load_missing', '_keys_to_ignore_on_load_unexpected', '_keys_to_ignore_on_save', '_load_from_state_dict', '_load_pretrained_model', '_load_pretrained_model_low_mem', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_initialize_input_ids_for_generation', '_maybe_warn_non_full_backward_hook', '_merge_criteria_processor_list', '_modules', '_named_members', '_no_split_modules', '_non_persistent_buffers_set', '_parameters', '_pp_plan', '_pp_plan', '_prepare_attention_mask_for_generation', '_prepare_cache_for_generation', '_prepare_decoder_input_ids_for_generation', '_prepare_encoder_decoder_kwargs_for_generation', '_prepare_generated_length', '_prepare_generation_config', '_prepare_model_inputs', '_prepare_special_tokens', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_cache', '_replicate_for_data_parallel', '_resize_token_embeddings', '_sample', '_save_to_state_dict', '_set_default_torch_dtype', '_set_gradient_checkpointing', '_skip_keys_device_placement', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_supports_attention_backend', '_supports_cache_class', '_supports_default_dynamic_cache', '_supports_flash_attn_2', '_supports_flex_attn', '_supports_logits_to_keep', '_supports_quantized_cache', '_supports_sdpa', '_supports_static_cache', '_temporary_reorder_cache', '_tie_encoder_decoder_weights', '_tie_or_clone_weights', '_tied_weights_keys', '_tied_weights_keys', '_tp_plan', '_tp_plan', '_update_model_kwargs_for_generation', '_upload_modified_files', '_validate_assistant', '_validate_generated_length', '_validate_model_class', '_validate_model_kwargs', '_version', '_wrapped_call_impl', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags', 'add_module', 'apply', 'base_model', 'base_model_prefix', 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'compile', 'compute_transition_scores', 'config', 'config_class', 'cpu', 'create_extended_attention_mask_for_decoder', 'cuda', 'delete_adapter', 'dequantize', 'device', 'disable_adapters', 'disable_input_require_grads', 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'enable_adapters', 'enable_input_require_grads', 'estimate_tokens', 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'framework', 'from_pretrained', 'generate', 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_compiled_call', 'get_decoder', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_image_features', 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter', 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'half', 'heal_tokens', 'init_weights', 'invert_attention_mask', 'ipu', 'is_backend_compatible', 'is_gradient_checkpointing', 'is_parallelizable', 'language_model', 'load_adapter', 'load_state_dict', 'loss_function', 'loss_type', 'main_input_name', 'model_tags', 'modules', 'mtia', 'multi_modal_projector', 'name_or_path', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_parameters', 'pad_token_id', 'parameters', 'post_init', 'prepare_inputs_for_generation', 'prune_heads', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'save_pretrained', 'set_adapter', 'set_decoder', 'set_extra_state', 'set_input_embeddings', 'set_output_embeddings', 'set_submodule', 'share_memory', 'state_dict', 'supports_gradient_checkpointing', 'supports_pp_plan', 'supports_tp_plan', 'tensor_parallel', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training', 'type', 'vision_tower', 'vocab_size', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']\n",
      "2025-03-19 06:49:36,205 - INFO - Model config: LlavaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"xtuner/llava-phi-3-mini-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlavaForConditionalGeneration\"\n",
      "  ],\n",
      "  \"ignore_index\": -100,\n",
      "  \"image_seq_length\": 576,\n",
      "  \"image_token_index\": 32038,\n",
      "  \"model_type\": \"llava\",\n",
      "  \"multimodal_projector_bias\": true,\n",
      "  \"pad_token_id\": 32039,\n",
      "  \"projector_hidden_act\": \"gelu\",\n",
      "  \"text_config\": {\n",
      "    \"_attn_implementation_autoset\": false,\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"LlamaForCausalLM\"\n",
      "    ],\n",
      "    \"attention_bias\": false,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 1,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 32000,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"head_dim\": 96,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 3072,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 8192,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 4096,\n",
      "    \"min_length\": 0,\n",
      "    \"mlp_bias\": false,\n",
      "    \"model_type\": \"llama\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 32,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 32,\n",
      "    \"num_key_value_heads\": 32,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"original_max_position_embeddings\": 4096,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 32000,\n",
      "    \"prefix\": null,\n",
      "    \"pretraining_tp\": 1,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"rms_norm_eps\": 1e-05,\n",
      "    \"rope_scaling\": null,\n",
      "    \"rope_theta\": 10000.0,\n",
      "    \"sep_token_id\": null,\n",
      "    \"sliding_window\": 2048,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": false,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"float32\",\n",
      "    \"torchscript\": false,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 32064\n",
      "  },\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"vision_config\": {\n",
      "    \"_attn_implementation_autoset\": false,\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"CLIPVisionModel\"\n",
      "    ],\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"dropout\": 0.0,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"hidden_act\": \"quick_gelu\",\n",
      "    \"hidden_size\": 1024,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"image_size\": 336,\n",
      "    \"initializer_factor\": 1.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 4096,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"clip_vision_model\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 24,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"patch_size\": 14,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"projection_dim\": 768,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"float32\",\n",
      "    \"torchscript\": false,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false\n",
      "  },\n",
      "  \"vision_feature_layer\": -2,\n",
      "  \"vision_feature_select_strategy\": \"default\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e0586007eb450e9e2d0172970eac63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af5b7b0dfbd4325b044f048cadd0849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/8.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee6782dcc1d4ae78f2b4d02199cebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139904815c8a480f8e6b9676cfe6b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71773829971e4a4c8feab360458632f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/978 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0718523de9e4a71baaf0674cadb6734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:49:37,302 - INFO - Patched processor.image_processor to add patch_size=14\n",
      "2025-03-19 06:49:37,303 - INFO - Found 13 video files to process\n",
      "2025-03-19 06:49:37,303 - INFO - Processing videos and extracting embeddings...\n",
      "2025-03-19 06:49:37,303 - INFO - Testing with video: videos_new/269.mp4\n",
      "2025-03-19 06:49:38,524 - INFO - Frames extracted: (8, 224, 224, 3)\n",
      "2025-03-19 06:49:38,570 - INFO - Manual processing successful, keys: dict_keys(['pixel_values', 'input_ids', 'attention_mask'])\n",
      "2025-03-19 06:49:38,570 - INFO - Trying to access vision tower...\n",
      "2025-03-19 06:49:38,571 - INFO - Found vision_tower\n",
      "2025-03-19 06:49:38,571 - INFO - Vision tower access successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e021fe22ef1416db15bca23713d73ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding Videos:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:51:47,143 - INFO - Embeddings saved to video_embeddings_mini_llama.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from transformers import LlavaForConditionalGeneration, AutoProcessor\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import gc  # For garbage collection\n",
    "import logging\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_video_frames(video_path, max_frames=8, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract frames from a video and resize them to a consistent size.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        max_frames (int): Maximum number of frames to extract.\n",
    "        target_size (tuple): (width, height) to resize frames to.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Extracted frames of shape (num_frames, height, width, 3).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # Check if the video opened successfully\n",
    "        if not cap.isOpened():\n",
    "            logger.error(f\"Could not open video: {video_path}\")\n",
    "            raise ValueError(f\"Could not open video: {video_path}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Handle videos with unknown frame count\n",
    "        if total_frames <= 0:\n",
    "            # Count frames manually\n",
    "            total_frames = 0\n",
    "            while True:\n",
    "                ret, _ = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                total_frames += 1\n",
    "            # Reset video to beginning\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "        # If still no frames, return a dummy frame\n",
    "        if total_frames == 0:\n",
    "            logger.warning(f\"No frames found in {video_path}, returning dummy frame\")\n",
    "            height, width = target_size[1], target_size[0]\n",
    "            dummy_frame = np.zeros((1, height, width, 3), dtype=np.uint8)\n",
    "            cap.release()\n",
    "            return dummy_frame\n",
    "        \n",
    "        # Calculate which frames to extract (uniform sampling)\n",
    "        num_frames = min(max_frames, total_frames)\n",
    "        \n",
    "        if num_frames == 1:\n",
    "            frame_indices = [0]\n",
    "        else:\n",
    "            frame_indices = [int(i * (total_frames - 1) / (num_frames - 1)) for i in range(num_frames)]\n",
    "        \n",
    "        # Extract the selected frames\n",
    "        frames = []\n",
    "        for idx in frame_indices:\n",
    "            # Set position to the desired frame\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                # Resize to target size for consistency\n",
    "                frame_resized = cv2.resize(frame, target_size)\n",
    "                # Convert BGR to RGB (OpenCV uses BGR, but most models expect RGB)\n",
    "                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame_rgb)\n",
    "            else:\n",
    "                # If frame reading failed, add a blank frame\n",
    "                frames.append(np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8))\n",
    "        \n",
    "        # Release the video capture object\n",
    "        cap.release()\n",
    "        \n",
    "        # If no frames were successfully extracted, return a dummy frame\n",
    "        if len(frames) == 0:\n",
    "            logger.warning(f\"No frames were successfully extracted from {video_path}\")\n",
    "            dummy_frame = np.zeros((1, target_size[1], target_size[0], 3), dtype=np.uint8)\n",
    "            return dummy_frame\n",
    "        \n",
    "        # Make sure we have the requested number of frames\n",
    "        while len(frames) < max_frames and len(frames) > 0:\n",
    "            frames.append(frames[-1].copy())  # Duplicate the last frame\n",
    "        \n",
    "        # Stack frames into a single array\n",
    "        frames_array = np.stack(frames)\n",
    "        \n",
    "        return frames_array\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading frames from {video_path}: {str(e)}\")\n",
    "        # Return a dummy frame if extraction fails\n",
    "        dummy_frame = np.zeros((1, target_size[1], target_size[0], 3), dtype=np.uint8)\n",
    "        return dummy_frame\n",
    "\n",
    "def manual_process_frames(processor, frames, text):\n",
    "    \"\"\"\n",
    "    Manually process frames to work around the patch_size bug in the LLaVA processor.\n",
    "    \n",
    "    This function emulates what the processor does but ensures the patch_size is set correctly.\n",
    "    \"\"\"\n",
    "    # First ensure processor.image_processor exists\n",
    "    if not hasattr(processor, 'image_processor'):\n",
    "        raise ValueError(\"Processor does not have an image_processor attribute\")\n",
    "    \n",
    "    # Process the images with the image processor\n",
    "    image_inputs = processor.image_processor(images=frames, return_tensors=\"pt\")\n",
    "    \n",
    "    # Process the text with the tokenizer\n",
    "    text_inputs = processor.tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Combine the outputs\n",
    "    inputs = {\n",
    "        \"pixel_values\": image_inputs.pixel_values,\n",
    "        \"input_ids\": text_inputs.input_ids,\n",
    "        \"attention_mask\": text_inputs.attention_mask\n",
    "    }\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "def extract_video_embedding(model, processor, video_path, device):\n",
    "    \"\"\"\n",
    "    Extract embedding for a single video with the patched processor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract frames using OpenCV (resized to standard size)\n",
    "        target_size = (224, 224)  # Common image size for vision models\n",
    "        video = extract_video_frames(video_path, max_frames=8, target_size=target_size)\n",
    "        \n",
    "        # Prepare prompt\n",
    "        prompt = \"USER: <image>\\nDescribe this video. ASSISTANT:\"\n",
    "        \n",
    "        # Use manual processing to avoid the patch_size bug\n",
    "        inputs = manual_process_frames(processor, video, prompt)\n",
    "        \n",
    "        # Move inputs to device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get embedding\n",
    "        with torch.no_grad():\n",
    "            # Access the vision_tower directly from the model\n",
    "            # Different LLaVA models may have different attribute names\n",
    "            if hasattr(model, 'vision_tower'):\n",
    "                vision_tower = model.vision_tower\n",
    "            elif hasattr(model, 'model') and hasattr(model.model, 'vision_tower'):\n",
    "                vision_tower = model.model.vision_tower\n",
    "            elif hasattr(model, 'vision_model'):\n",
    "                vision_tower = model.vision_model\n",
    "            else:\n",
    "                # Print model attributes to help diagnose\n",
    "                logger.info(f\"Model attributes: {dir(model)}\")\n",
    "                raise AttributeError(\"Could not find vision tower in model\")\n",
    "            \n",
    "            # Get outputs from vision tower\n",
    "            outputs = vision_tower(inputs[\"pixel_values\"])\n",
    "            \n",
    "            # Extract visual features\n",
    "            if hasattr(outputs, \"pooler_output\"):\n",
    "                embedding = outputs.pooler_output.cpu().numpy()\n",
    "            elif hasattr(outputs, \"last_hidden_state\"):\n",
    "                # Use the [CLS] token or average all tokens\n",
    "                last_hidden_state = outputs.last_hidden_state\n",
    "                embedding = last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            else:\n",
    "                # Handle case where outputs is the tensor directly\n",
    "                if isinstance(outputs, torch.Tensor):\n",
    "                    embedding = outputs.mean(dim=1).cpu().numpy()\n",
    "                else:\n",
    "                    logger.info(f\"Output attributes: {dir(outputs)}\")\n",
    "                    raise ValueError(\"Could not extract embedding from vision tower outputs\")\n",
    "        \n",
    "        # Clear CUDA cache to free memory\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return embedding\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {video_path}: {str(e)}\")\n",
    "        # Return a zero vector of the expected dimension\n",
    "        if hasattr(model.config, \"hidden_size\"):\n",
    "            embedding_size = model.config.hidden_size\n",
    "        else:\n",
    "            embedding_size = 768  # Default fallback\n",
    "        return np.zeros((1, embedding_size))\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize model and processor\n",
    "    model_name = \"xtuner/llava-phi-3-mini-hf\"\n",
    "    logger.info(f\"Loading model: {model_name}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\" if device.type == \"cuda\" else None,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    model.eval()\n",
    "    \n",
    "    # Print model structure to help debug\n",
    "    logger.info(f\"Model keys: {dir(model)}\")\n",
    "    if hasattr(model, 'config'):\n",
    "        logger.info(f\"Model config: {model.config}\")\n",
    "\n",
    "    # Load processor\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "    processor.tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    # Patch the processor's image_processor to ensure it has a patch_size\n",
    "    # LLaVA Phi uses 14x14 patch size typically\n",
    "    if hasattr(processor, 'image_processor') and not hasattr(processor.image_processor, 'patch_size'):\n",
    "        processor.image_processor.patch_size = 14\n",
    "        logger.info(\"Patched processor.image_processor to add patch_size=14\")\n",
    "    \n",
    "    # Directory containing videos\n",
    "    videos_dir = \"videos_new\"\n",
    "    if not os.path.isdir(videos_dir):\n",
    "        raise ValueError(f\"Directory '{videos_dir}' does not exist.\")\n",
    "\n",
    "    # Supported video extensions\n",
    "    video_extensions = {\".mp4\", \".mov\", \".avi\", \".mkv\"}\n",
    "\n",
    "    # List all video files\n",
    "    video_files = [\n",
    "        f for f in os.listdir(videos_dir)\n",
    "        if os.path.splitext(f)[1].lower() in video_extensions\n",
    "    ]\n",
    "\n",
    "    if not video_files:\n",
    "        raise ValueError(f\"No video files found in directory '{videos_dir}'.\")\n",
    "\n",
    "    # Prepare list to hold filename and embeddings\n",
    "    data = []\n",
    "\n",
    "    logger.info(f\"Found {len(video_files)} video files to process\")\n",
    "    logger.info(\"Processing videos and extracting embeddings...\")\n",
    "    \n",
    "    # Process a single video first to debug\n",
    "    if video_files:\n",
    "        test_video = video_files[0]\n",
    "        test_path = os.path.join(videos_dir, test_video)\n",
    "        logger.info(f\"Testing with video: {test_path}\")\n",
    "        try:\n",
    "            # Get frames\n",
    "            frames = extract_video_frames(test_path)\n",
    "            logger.info(f\"Frames extracted: {frames.shape}\")\n",
    "            \n",
    "            # Process manually\n",
    "            prompt = \"USER: <image>\\nDescribe this video. ASSISTANT:\"\n",
    "            inputs = manual_process_frames(processor, frames, prompt)\n",
    "            logger.info(f\"Manual processing successful, keys: {inputs.keys()}\")\n",
    "            \n",
    "            # Do a test run with vision tower access\n",
    "            logger.info(\"Trying to access vision tower...\")\n",
    "            with torch.no_grad():\n",
    "                if hasattr(model, 'vision_model'):\n",
    "                    logger.info(\"Found vision_model\")\n",
    "                    vision_tower = model.vision_model\n",
    "                elif hasattr(model, 'model') and hasattr(model.model, 'vision_tower'):\n",
    "                    logger.info(\"Found model.model.vision_tower\")\n",
    "                    vision_tower = model.model.vision_tower\n",
    "                elif hasattr(model, 'vision_tower'):\n",
    "                    logger.info(\"Found vision_tower\")\n",
    "                    vision_tower = model.vision_tower\n",
    "                else:\n",
    "                    logger.info(f\"Model dir: {dir(model)}\")\n",
    "                    if hasattr(model, 'model'):\n",
    "                        logger.info(f\"Model.model dir: {dir(model.model)}\")\n",
    "                    raise ValueError(\"Could not find vision tower\")\n",
    "                \n",
    "                logger.info(\"Vision tower access successful\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Test processing failed: {e}\")\n",
    "    \n",
    "    # Process all videos\n",
    "    for video_file in tqdm(video_files, desc=\"Embedding Videos\"):\n",
    "        video_path = os.path.join(videos_dir, video_file)\n",
    "        filename, _ = os.path.splitext(video_file)\n",
    "        try:\n",
    "            # Process the video and get embedding\n",
    "            embedding = extract_video_embedding(model, processor, video_path, device)\n",
    "            \n",
    "            # Flatten and convert embedding to list for CSV\n",
    "            embedding_list = embedding.flatten().tolist()\n",
    "            \n",
    "            data.append({\n",
    "                \"filename\": filename,\n",
    "                \"embedding\": embedding_list\n",
    "            })\n",
    "            \n",
    "            # Force garbage collection to free memory\n",
    "            gc.collect()\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {video_file}: {e}\")\n",
    "            # Add a placeholder with zeros to maintain the list of filenames\n",
    "            if hasattr(model.config, \"hidden_size\"):\n",
    "                embedding_size = model.config.hidden_size\n",
    "            else:\n",
    "                embedding_size = 768  # Default fallback size\n",
    "                \n",
    "            data.append({\n",
    "                \"filename\": filename,\n",
    "                \"embedding\": [0.0] * embedding_size\n",
    "            })\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv = \"video_embeddings_mini_llama.csv\"\n",
    "    # To store embeddings as strings, join the list elements\n",
    "    df['embedding'] = df['embedding'].apply(lambda x: \",\".join(map(str, x)))\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    logger.info(f\"Embeddings saved to {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbTrRWwmxGtY"
   },
   "source": [
    "### Video ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h9FqPvqExJO7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "import subprocess\n",
    "import gc\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Whisper supported languages\n",
    "WHISPER_LANGUAGES = {\n",
    "    \"en\": \"English\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"lt\": \"Lithuanian\",\n",
    "    \"la\": \"Latin\",\n",
    "    \"mi\": \"Maori\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"cy\": \"Welsh\",\n",
    "    \"sk\": \"Slovak\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"lv\": \"Latvian\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"az\": \"Azerbaijani\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"kn\": \"Kannada\",\n",
    "    \"et\": \"Estonian\",\n",
    "    \"mk\": \"Macedonian\",\n",
    "    \"br\": \"Breton\",\n",
    "    \"eu\": \"Basque\",\n",
    "    \"is\": \"Icelandic\",\n",
    "    \"hy\": \"Armenian\",\n",
    "    \"ne\": \"Nepali\",\n",
    "    \"mn\": \"Mongolian\",\n",
    "    \"bs\": \"Bosnian\",\n",
    "    \"kk\": \"Kazakh\",\n",
    "    \"sq\": \"Albanian\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"gl\": \"Galician\",\n",
    "    \"mr\": \"Marathi\",\n",
    "    \"pa\": \"Punjabi\",\n",
    "    \"si\": \"Sinhala\",\n",
    "    \"km\": \"Khmer\",\n",
    "    \"sn\": \"Shona\",\n",
    "    \"yo\": \"Yoruba\",\n",
    "    \"so\": \"Somali\",\n",
    "    \"af\": \"Afrikaans\",\n",
    "    \"oc\": \"Occitan\",\n",
    "    \"ka\": \"Georgian\",\n",
    "    \"be\": \"Belarusian\",\n",
    "    \"tg\": \"Tajik\",\n",
    "    \"sd\": \"Sindhi\",\n",
    "    \"gu\": \"Gujarati\",\n",
    "    \"am\": \"Amharic\",\n",
    "    \"yi\": \"Yiddish\",\n",
    "    \"lo\": \"Lao\",\n",
    "    \"uz\": \"Uzbek\",\n",
    "    \"fo\": \"Faroese\",\n",
    "    \"ht\": \"Haitian Creole\",\n",
    "    \"ps\": \"Pashto\",\n",
    "    \"tk\": \"Turkmen\",\n",
    "    \"nn\": \"Nynorsk\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"sa\": \"Sanskrit\",\n",
    "    \"lb\": \"Luxembourgish\",\n",
    "    \"my\": \"Myanmar\",\n",
    "    \"bo\": \"Tibetan\",\n",
    "    \"tl\": \"Tagalog\",\n",
    "    \"mg\": \"Malagasy\",\n",
    "    \"as\": \"Assamese\",\n",
    "    \"tt\": \"Tatar\",\n",
    "    \"haw\": \"Hawaiian\",\n",
    "    \"ln\": \"Lingala\",\n",
    "    \"ha\": \"Hausa\",\n",
    "    \"ba\": \"Bashkir\",\n",
    "    \"jw\": \"Javanese\",\n",
    "    \"su\": \"Sundanese\",\n",
    "}\n",
    "\n",
    "def extract_audio_directly(video_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    Use direct FFmpeg command to extract audio without any processing.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        output_dir (str, optional): Directory to save the output. If None, uses temp dir.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the extracted audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Setup output path\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "            output_path = os.path.join(output_dir, f\"{video_name}.wav\")\n",
    "        else:\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "            output_path = os.path.join(temp_dir, f\"{video_name}.wav\")\n",
    "        \n",
    "        logger.info(f\"Extracting original audio directly from {video_path}\")\n",
    "        \n",
    "        # Basic command to extract audio with minimal processing\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', video_path,  # Input file\n",
    "            '-vn',             # No video\n",
    "            '-acodec', 'pcm_s16le',  # PCM format (standard for WAV)\n",
    "            '-ar', '16000',    # 16kHz (Whisper's expected sample rate)\n",
    "            '-ac', '1',        # Mono\n",
    "            '-y',              # Overwrite if exists\n",
    "            output_path        # Output file\n",
    "        ]\n",
    "        \n",
    "        # Run FFmpeg command\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        \n",
    "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
    "            logger.info(f\"Audio extracted successfully to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            logger.error(\"Failed to create valid audio file\")\n",
    "            raise ValueError(\"Audio extraction produced empty file\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting audio directly: {e}\")\n",
    "        raise\n",
    "\n",
    "def transcribe_audio_in_chunks(transcribe_function, audio_path, max_retry=3):\n",
    "    \"\"\"\n",
    "    Handle transcription by retrying or providing fallback values.\n",
    "    \n",
    "    Args:\n",
    "        transcribe_function: Function to use for transcription\n",
    "        audio_path: Path to the audio file\n",
    "        max_retry: Maximum number of retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        dict: Transcription result or error message\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retry):\n",
    "        try:\n",
    "            logger.info(f\"Transcription attempt {attempt+1}/{max_retry}\")\n",
    "            result = transcribe_function(audio_path)\n",
    "            # If successful, return the result\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # If all attempts failed, return error message\n",
    "    return {\"text\": \"Failed to transcribe after multiple attempts\", \"language\": None}\n",
    "\n",
    "def process_single_video(video_path, model_size=\"small\", language=None, translate=False, \n",
    "                         output_dir=None, keep_audio=False):\n",
    "    \"\"\"\n",
    "    Process a single video file to extract audio and transcribe it.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        model_size (str): Size of the Whisper model to use.\n",
    "        language (str): Language code to force (e.g., \"en\", \"fr\"). If None, auto-detect.\n",
    "        translate (bool): Whether to translate non-English speech to English.\n",
    "        output_dir (str, optional): Directory to save the audio file.\n",
    "        keep_audio (bool): Whether to keep the extracted audio file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains transcription text and detected language.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract audio\n",
    "        audio_path = extract_audio_directly(video_path, output_dir if keep_audio else None)\n",
    "        \n",
    "        # Use a separate function to handle transcription to avoid kernel crashes \n",
    "        # if the import fails\n",
    "        def setup_and_transcribe(audio_path):\n",
    "            # Import whisper only when needed to avoid memory pressure\n",
    "            try:\n",
    "                import whisper\n",
    "                \n",
    "                # Load the model (specifying a smaller model to prevent crashes)\n",
    "                logger.info(f\"Loading whisper {model_size} model\")\n",
    "                model = whisper.load_model(model_size)\n",
    "                \n",
    "                # Set task based on whether translation is requested\n",
    "                task = \"translate\" if translate else \"transcribe\"\n",
    "                \n",
    "                # Detect language if not specified\n",
    "                if language is None:\n",
    "                    logger.info(\"Detecting language...\")\n",
    "                    # Use a smaller portion of audio for language detection\n",
    "                    audio = whisper.load_audio(audio_path)\n",
    "                    audio = whisper.pad_or_trim(audio)\n",
    "                    \n",
    "                    # Get the log mel spectrogram\n",
    "                    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "                    \n",
    "                    # Detect the language\n",
    "                    _, probs = model.detect_language(mel)\n",
    "                    detected_lang = max(probs, key=probs.get)\n",
    "                    \n",
    "                    logger.info(f\"Detected language: {detected_lang} ({WHISPER_LANGUAGES.get(detected_lang, 'Unknown')})\")\n",
    "                    detected_language = detected_lang\n",
    "                else:\n",
    "                    logger.info(f\"Using specified language: {language}\")\n",
    "                    detected_language = language\n",
    "                \n",
    "                # Transcribe the audio\n",
    "                logger.info(f\"Transcribing {audio_path} in {detected_language} (task: {task})\")\n",
    "                result = model.transcribe(\n",
    "                    audio_path, \n",
    "                    language=detected_language,\n",
    "                    task=task,\n",
    "                    fp16=False  # Disable fp16 for stability\n",
    "                )\n",
    "                \n",
    "                # Free memory immediately after transcription\n",
    "                del model\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                \n",
    "                return {\n",
    "                    \"text\": result[\"text\"],\n",
    "                    \"language\": detected_language\n",
    "                }\n",
    "            except ImportError:\n",
    "                logger.error(\"Failed to import whisper. Make sure it's installed.\")\n",
    "                return {\"text\": \"Error: Whisper not installed\", \"language\": None}\n",
    "        \n",
    "        # Transcribe with retries\n",
    "        result = transcribe_audio_in_chunks(setup_and_transcribe, audio_path)\n",
    "        \n",
    "        # Clean up if not keeping audio\n",
    "        if not keep_audio and output_dir is None and os.path.exists(audio_path):\n",
    "            os.remove(audio_path)\n",
    "            logger.info(f\"Deleted temporary audio file: {audio_path}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing video {video_path}: {e}\")\n",
    "        return {\"text\": f\"Error: {str(e)}\", \"language\": None}\n",
    "\n",
    "def transcribe_videos(videos_dir=\"videos_new\", output_csv=\"video_transcriptions.csv\", \n",
    "                      audio_dir=None, keep_audio=False, model_size=\"small\",\n",
    "                      language=None, translate=False):\n",
    "    \"\"\"\n",
    "    Transcribe all videos in a directory.\n",
    "    \n",
    "    Args:\n",
    "        videos_dir (str): Directory containing videos.\n",
    "        output_csv (str): Output CSV file path.\n",
    "        audio_dir (str, optional): Directory to save audio files.\n",
    "        keep_audio (bool): Whether to keep the extracted audio files.\n",
    "        model_size (str): Whisper model size ('tiny', 'base', 'small', 'medium').\n",
    "        language (str, optional): Language code to force. If None, auto-detect.\n",
    "        translate (bool): Whether to translate non-English speech to English.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with transcriptions.\n",
    "    \"\"\"\n",
    "    # List videos\n",
    "    if not os.path.isdir(videos_dir):\n",
    "        raise ValueError(f\"Directory not found: {videos_dir}\")\n",
    "    \n",
    "    video_extensions = {\".mp4\", \".mov\", \".avi\", \".mkv\"}\n",
    "    video_files = [\n",
    "        f for f in os.listdir(videos_dir)\n",
    "        if os.path.splitext(f)[1].lower() in video_extensions\n",
    "    ]\n",
    "    \n",
    "    if not video_files:\n",
    "        raise ValueError(f\"No video files found in {videos_dir}\")\n",
    "    \n",
    "    logger.info(f\"Found {len(video_files)} videos in {videos_dir}\")\n",
    "    \n",
    "    # Install whisper if needed\n",
    "    try:\n",
    "        logger.info(\"Checking if whisper is installed...\")\n",
    "        import whisper\n",
    "        logger.info(\"Whisper is already installed\")\n",
    "    except ImportError:\n",
    "        logger.info(\"Installing whisper...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"openai-whisper\"])\n",
    "        logger.info(\"Whisper installed successfully\")\n",
    "    \n",
    "    # Process each video\n",
    "    results = []\n",
    "    for video_file in tqdm(video_files, desc=\"Processing Videos\"):\n",
    "        video_path = os.path.join(videos_dir, video_file)\n",
    "        filename, _ = os.path.splitext(video_file)\n",
    "        \n",
    "        try:\n",
    "            # Process the video\n",
    "            result = process_single_video(\n",
    "                video_path=video_path,\n",
    "                model_size=model_size,\n",
    "                language=language,\n",
    "                translate=translate,\n",
    "                output_dir=audio_dir,\n",
    "                keep_audio=keep_audio\n",
    "            )\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                \"filename\": filename,\n",
    "                \"transcription\": result[\"text\"],\n",
    "                \"detected_language\": result[\"language\"],\n",
    "                \"language_name\": WHISPER_LANGUAGES.get(result[\"language\"], \"Unknown\")\n",
    "            })\n",
    "            \n",
    "            logger.info(f\"Processed {filename}: {result['text'][:50]}...\")\n",
    "            logger.info(f\"Detected language: {result['language']} ({WHISPER_LANGUAGES.get(result['language'], 'Unknown')})\")\n",
    "            \n",
    "            # Free memory\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {filename}: {e}\")\n",
    "            results.append({\n",
    "                \"filename\": filename,\n",
    "                \"transcription\": f\"Error: {str(e)}\",\n",
    "                \"detected_language\": None,\n",
    "                \"language_name\": \"Unknown\"\n",
    "            })\n",
    "            \n",
    "        # Save results after each video to prevent losing progress\n",
    "        pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "        logger.info(f\"Progress saved to {output_csv}\")\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV (final save)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    logger.info(f\"Saved transcriptions to {output_csv}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:51:48,490 - INFO - Found 13 videos in videos_new\n",
      "2025-03-19 06:51:48,490 - INFO - Checking if whisper is installed...\n",
      "2025-03-19 06:51:49,540 - INFO - Whisper is already installed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2359faf98648b49b6504ed4f03df37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Videos:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:51:49,556 - INFO - Extracting original audio directly from videos_new/269.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:51:49,861 - INFO - Audio extracted successfully to audio_files/269.wav\n",
      "2025-03-19 06:51:49,861 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:51:49,862 - INFO - Loading whisper small model\n",
      "2025-03-19 06:51:53,483 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:51:55,206 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:51:55,207 - INFO - Transcribing audio_files/269.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:52:12,710 - INFO - Processed 269:  Hi everyone, welcome to our NYU Shanghai campus t...\n",
      "2025-03-19 06:52:12,711 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:52:12,904 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:52:12,906 - INFO - Extracting original audio directly from videos_new/288.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:52:13,193 - INFO - Audio extracted successfully to audio_files/288.wav\n",
      "2025-03-19 06:52:13,194 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:52:13,194 - INFO - Loading whisper small model\n",
      "2025-03-19 06:52:16,608 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:52:18,091 - INFO - Detected language: sn (Shona)\n",
      "2025-03-19 06:52:18,093 - INFO - Transcribing audio_files/288.wav in sn (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:13,108 - INFO - Processed 288:  DIA ɥ � оС LEO із region sst  𝓍 subsequent � revi...\n",
      "2025-03-19 06:54:13,109 - INFO - Detected language: sn (Shona)\n",
      "2025-03-19 06:54:13,300 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:54:13,302 - INFO - Extracting original audio directly from videos_new/276.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:13,626 - INFO - Audio extracted successfully to audio_files/276.wav\n",
      "2025-03-19 06:54:13,627 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:54:13,627 - INFO - Loading whisper small model\n",
      "2025-03-19 06:54:16,984 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:18,452 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:54:18,454 - INFO - Transcribing audio_files/276.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:40,538 - INFO - Processed 276:  Welcome to our Dontor video presented by Kiki and...\n",
      "2025-03-19 06:54:40,539 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:54:40,730 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:54:40,732 - INFO - Extracting original audio directly from videos_new/283.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:40,925 - INFO - Audio extracted successfully to audio_files/283.wav\n",
      "2025-03-19 06:54:40,926 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:54:40,926 - INFO - Loading whisper small model\n",
      "2025-03-19 06:54:44,240 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:45,662 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:54:45,663 - INFO - Transcribing audio_files/283.wav in zh (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:47,554 - INFO - Processed 283: 小红书...\n",
      "2025-03-19 06:54:47,555 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:54:47,743 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:54:47,745 - INFO - Extracting original audio directly from videos_new/268.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:48,015 - INFO - Audio extracted successfully to audio_files/268.wav\n",
      "2025-03-19 06:54:48,015 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:54:48,016 - INFO - Loading whisper small model\n",
      "2025-03-19 06:54:51,258 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:54:52,714 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:54:52,715 - INFO - Transcribing audio_files/268.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 06:55:03,065 - INFO - Processed 268:  Welcome to NYU Shanghai's cafeteria. This is wher...\n",
      "2025-03-19 06:55:03,066 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:03,257 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:55:03,259 - INFO - Extracting original audio directly from videos_new/280.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:03,543 - INFO - Audio extracted successfully to audio_files/280.wav\n",
      "2025-03-19 06:55:03,544 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:55:03,544 - INFO - Loading whisper small model\n",
      "2025-03-19 06:55:06,781 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:08,239 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:08,240 - INFO - Transcribing audio_files/280.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:23,513 - INFO - Processed 280:  I'll do it again. I can't breathe. Hi! Hi! Let's ...\n",
      "2025-03-19 06:55:23,514 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:23,711 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:55:23,712 - INFO - Extracting original audio directly from videos_new/291.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:24,117 - INFO - Audio extracted successfully to audio_files/291.wav\n",
      "2025-03-19 06:55:24,118 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:55:24,118 - INFO - Loading whisper small model\n",
      "2025-03-19 06:55:27,404 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:28,880 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:28,881 - INFO - Transcribing audio_files/291.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:46,136 - INFO - Processed 291:  Hello guys, welcome and welcome back to Fostering...\n",
      "2025-03-19 06:55:46,137 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:46,334 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:55:46,336 - INFO - Extracting original audio directly from videos_new/278.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:46,679 - INFO - Audio extracted successfully to audio_files/278.wav\n",
      "2025-03-19 06:55:46,680 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:55:46,680 - INFO - Loading whisper small model\n",
      "2025-03-19 06:55:50,007 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:55:51,482 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:55:51,483 - INFO - Transcribing audio_files/278.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:04,560 - INFO - Processed 278:  Welcome to the Tour of Stern, presented to you by...\n",
      "2025-03-19 06:56:04,560 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:56:04,757 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:56:04,759 - INFO - Extracting original audio directly from videos_new/271.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:05,111 - INFO - Audio extracted successfully to audio_files/271.wav\n",
      "2025-03-19 06:56:05,111 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:56:05,112 - INFO - Loading whisper small model\n",
      "2025-03-19 06:56:08,341 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:09,816 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:56:09,817 - INFO - Transcribing audio_files/271.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:27,883 - INFO - Processed 271:  Hey guys, today I will take you on a tour of the ...\n",
      "2025-03-19 06:56:27,884 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:56:28,079 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:56:28,080 - INFO - Extracting original audio directly from videos_new/289.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:28,370 - INFO - Audio extracted successfully to audio_files/289.wav\n",
      "2025-03-19 06:56:28,371 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:56:28,371 - INFO - Loading whisper small model\n",
      "2025-03-19 06:56:31,719 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:33,191 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:56:33,191 - INFO - Transcribing audio_files/289.wav in en (task: transcribe)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:48,182 - INFO - Processed 289:  Today's vlog is kind of special. Let's celebrate ...\n",
      "2025-03-19 06:56:48,183 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:56:48,377 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:56:48,379 - INFO - Extracting original audio directly from videos_new/282.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:48,667 - INFO - Audio extracted successfully to audio_files/282.wav\n",
      "2025-03-19 06:56:48,668 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:56:48,668 - INFO - Loading whisper small model\n",
      "2025-03-19 06:56:51,936 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:56:53,403 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:56:53,404 - INFO - Transcribing audio_files/282.wav in zh (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:05,236 - INFO - Processed 282: 3 2 1參加各種有趣的活動比如紐約的城市荒光上海的地方然後還有各種工作比如我每次都在Bethler...\n",
      "2025-03-19 06:57:05,237 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:57:05,430 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:57:05,431 - INFO - Extracting original audio directly from videos_new/270.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:05,637 - INFO - Audio extracted successfully to audio_files/270.wav\n",
      "2025-03-19 06:57:05,638 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:57:05,638 - INFO - Loading whisper small model\n",
      "2025-03-19 06:57:08,895 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:10,324 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:57:10,325 - INFO - Transcribing audio_files/270.wav in zh (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:13,660 - INFO - Processed 270: And I saidCome here, take meSomewhere we can be mo...\n",
      "2025-03-19 06:57:13,661 - INFO - Detected language: zh (Chinese)\n",
      "2025-03-19 06:57:13,854 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:57:13,856 - INFO - Extracting original audio directly from videos_new/274.mp4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:14,142 - INFO - Audio extracted successfully to audio_files/274.wav\n",
      "2025-03-19 06:57:14,142 - INFO - Transcription attempt 1/3\n",
      "2025-03-19 06:57:14,143 - INFO - Loading whisper small model\n",
      "2025-03-19 06:57:17,613 - INFO - Detecting language...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:19,088 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:57:19,089 - INFO - Transcribing audio_files/274.wav in en (task: transcribe)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-03-19 06:57:34,777 - INFO - Processed 274:  Hi there, as some of you may choose to live off c...\n",
      "2025-03-19 06:57:34,777 - INFO - Detected language: en (English)\n",
      "2025-03-19 06:57:34,973 - INFO - Progress saved to transcriptions.csv\n",
      "2025-03-19 06:57:34,976 - INFO - Saved transcriptions to transcriptions.csv\n"
     ]
    }
   ],
   "source": [
    "df = transcribe_videos(\n",
    "    videos_dir=\"videos_new\",\n",
    "    output_csv=\"transcriptions.csv\",\n",
    "    audio_dir=\"audio_files\",\n",
    "    keep_audio=True,\n",
    "    model_size=\"small\", # Options: tiny, base, small, medium, large\n",
    "    language=None,  # Auto-detect language (you can set a language if all your videos are of one language)\n",
    "    translate=False  # Set to True to translate non-English to English\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31fNy9nhEHMM"
   },
   "source": [
    "### Merge into one .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dkR9_VnxEHMM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "df_transcriptions = pd.read_csv(\"transcriptions.csv\")\n",
    "df_embeddings = pd.read_csv(\"video_embeddings_mini_llama.csv\")\n",
    "df_metadata = pd.read_csv(\"video_features_new.csv\")\n",
    "\n",
    "# Convert the 'filename' columns to string in all dataframes\n",
    "df_transcriptions[\"filename\"] = df_transcriptions[\"filename\"].astype(str)\n",
    "df_embeddings[\"filename\"] = df_embeddings[\"filename\"].astype(str)\n",
    "df_metadata[\"filename\"] = df_metadata[\"filename\"].astype(str)\n",
    "\n",
    "# Remove the '.mp4' extension from the metadata filenames for a proper join\n",
    "df_metadata['filename'] = df_metadata['filename'].str.replace('.mp4', '', regex=False)\n",
    "\n",
    "# Merge the dataframes on the \"filename\" column\n",
    "df_merged = pd.merge(df_transcriptions, df_embeddings, on=\"filename\", how=\"outer\")\n",
    "df_merged = pd.merge(df_merged, df_metadata, on=\"filename\", how=\"outer\")\n",
    "\n",
    "# Write the merged DataFrame to a new CSV file\n",
    "df_merged.to_csv(\"combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully with 13 rows and 18 columns\n",
      "\n",
      "--- Data Overview ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   filename           13 non-null     int64  \n",
      " 1   transcription      13 non-null     object \n",
      " 2   detected_language  13 non-null     object \n",
      " 3   language_name      13 non-null     object \n",
      " 4   embedding          13 non-null     object \n",
      " 5   duration_seconds   13 non-null     float64\n",
      " 6   fps                13 non-null     float64\n",
      " 7   width              13 non-null     int64  \n",
      " 8   height             13 non-null     int64  \n",
      " 9   num_frames         13 non-null     int64  \n",
      " 10  file_size_MB       13 non-null     float64\n",
      " 11  codec              13 non-null     object \n",
      " 12  has_audio          13 non-null     bool   \n",
      " 13  audio_fps          13 non-null     float64\n",
      " 14  audio_channels     13 non-null     int64  \n",
      " 15  title              13 non-null     object \n",
      " 16  publish_time       13 non-null     object \n",
      " 17  likes              13 non-null     int64  \n",
      "dtypes: bool(1), float64(4), int64(6), object(7)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "--- First few rows ---\n",
      "   filename                                      transcription detected_language language_name                                          embedding  duration_seconds   fps  width  height  num_frames  file_size_MB codec  has_audio  audio_fps  audio_channels                      title publish_time  likes\n",
      "0       269   Hi everyone, welcome to our NYU Shanghai camp...                en       English  -0.45579758286476135,-0.06881476193666458,0.76...           101.634  30.0    720    1264        3049     14.542758  h264       True    44100.0               2    Campus Tour｜一起探索前滩校园吧～�        45582     59\n",
      "1       288   DIA ɥ � оС LEO із region sst  𝓍 subsequent � ...                sn         Shona  -0.07276651263237,0.9141224026679993,1.3050256...            78.234  30.0   1280     720        2347     13.197639  h264       True    44100.0               2    Company Visit | 凯迪拉克之旅�        45368     28\n",
      "2       276   Welcome to our Dontor video presented by Kiki...                en       English  -0.6746351718902588,-0.24911057949066162,-0.33...           102.425  33.0    720    1280        3380     14.541764  h264       True    44100.0               2  NYU Dormitory | 纽约大学宿舍巡礼�        45498    193\n",
      "3       283                                                小红书                zh       Chinese  0.32864487171173096,0.2789093255996704,0.58663...            11.667  30.0    720     958         350      0.996016  h264       True    44100.0               2           一年一度《专业团队》合照时间到�        45401     27\n",
      "4       268   Welcome to NYU Shanghai's cafeteria. This is ...                en       English  -1.110951542854309,-0.5740197896957397,0.78710...            65.600  30.0    720    1280        1968     11.035752  h264       True    44100.0               2             �️上海纽约大学食堂大揭秘�        45597     81\n",
      "\n",
      "--- Basic statistics ---\n",
      "         filename  duration_seconds        fps        width       height   num_frames  file_size_MB     audio_fps  audio_channels       likes\n",
      "count   13.000000         13.000000  13.000000    13.000000    13.000000    13.000000     13.000000     13.000000            13.0   13.000000\n",
      "mean   278.384615         66.587385  34.076923   763.076923  1186.307692  2361.923077     10.092857  44400.000000             2.0   53.153846\n",
      "std      7.890273         28.396847   9.543423   155.316055   183.898244  1414.084183      5.132252   1081.665383             0.0   46.048609\n",
      "min    268.000000         11.667000  30.000000   720.000000   720.000000   350.000000      0.996016  44100.000000             2.0   14.000000\n",
      "25%    271.000000         56.357000  30.000000   720.000000  1264.000000  1690.000000      4.940456  44100.000000             2.0   28.000000\n",
      "50%    278.000000         72.800000  30.000000   720.000000  1280.000000  2184.000000     11.556926  44100.000000             2.0   42.000000\n",
      "75%    283.000000         84.546000  30.000000   720.000000  1280.000000  3049.000000     14.494911  44100.000000             2.0   59.000000\n",
      "max    291.000000        102.425000  60.000000  1280.000000  1280.000000  5481.000000     16.612877  48000.000000             2.0  193.000000\n",
      "\n",
      "--- Missing values ---\n",
      "filename             0\n",
      "transcription        0\n",
      "detected_language    0\n",
      "language_name        0\n",
      "embedding            0\n",
      "duration_seconds     0\n",
      "fps                  0\n",
      "width                0\n",
      "height               0\n",
      "num_frames           0\n",
      "file_size_MB         0\n",
      "codec                0\n",
      "has_audio            0\n",
      "audio_fps            0\n",
      "audio_channels       0\n",
      "title                0\n",
      "publish_time         0\n",
      "likes                0\n",
      "dtype: int64\n",
      "=== Video Likes Prediction Model ===\n",
      "\n",
      "--- Processing embeddings ---\n",
      "Converting embeddings from string to numeric arrays...\n",
      "Embedding dimension: 8192\n",
      "Successfully created 8192 embedding feature columns\n",
      "\n",
      "--- Processing transcriptions ---\n",
      "Generating TF-IDF features from transcriptions...\n",
      "Added 10 TF-IDF SVD features\n",
      "\n",
      "--- Processing video metadata ---\n",
      "Successfully processed relative time from publish_time\n",
      "\n",
      "--- Preparing data for modeling ---\n",
      "Rows after dropping missing target values: 13\n",
      "Target variable statistics: min=14, max=193, mean=53.15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log-transformed target for modeling\n",
      "Selected 8217 numeric features and 7 categorical features\n",
      "Training set: 10 samples\n",
      "Test set: 3 samples\n",
      "\n",
      "--- Building prediction models ---\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Results:\n",
      "  R² Score: -0.0465\n",
      "  RMSE (log scale): 0.3847\n",
      "  MAE (log scale): 0.3384\n",
      "  RMSE (original scale): 14.2713\n",
      "  MAE (original scale): 13.1346\n",
      "\n",
      "Training GradientBoosting...\n",
      "GradientBoosting Results:\n",
      "  R² Score: 0.4085\n",
      "  RMSE (log scale): 0.2892\n",
      "  MAE (log scale): 0.2283\n",
      "  RMSE (original scale): 9.5197\n",
      "  MAE (original scale): 8.2100\n",
      "\n",
      "Training ElasticNet...\n",
      "ElasticNet Results:\n",
      "  R² Score: 0.1902\n",
      "  RMSE (log scale): 0.3384\n",
      "  MAE (log scale): 0.3088\n",
      "  RMSE (original scale): 12.1593\n",
      "  MAE (original scale): 11.7828\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Results:\n",
      "  R² Score: -0.3681\n",
      "  RMSE (log scale): 0.4398\n",
      "  MAE (log scale): 0.4207\n",
      "  RMSE (original scale): 28.7797\n",
      "  MAE (original scale): 23.9705\n",
      "\n",
      "Best model: GradientBoosting with R² = 0.4085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAI4CAYAAAB3OR9vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABWmElEQVR4nO3de5zdVX3v/9ebcGlADLdSI0RiS1BQMJppsA0qimlVKoZTIlioQLX8WrW29mALB065CKegbaWVXuDosUiLUhCVikYuNQiUABNEUkGQIlUuLYgQiKkhl8/vj/2NfDOZy54kk8mevJ6Px3649/qu9fmu794T582atfdOVSFJkiSpY5vxnoAkSZK0JTEgS5IkSS0GZEmSJKnFgCxJkiS1GJAlSZKkFgOyJEmS1GJAliRtcZLckuTVm/mcZyb5h+b+S5IsSzJpc85hc9qU15jkg0nO2xTzkrYEBmRpgmt+Aa69rUny363Hx26ic/xZku8meTbJd5K8e8DxmUkWJ1ne/O/MYWr9fZLnBsz76I2c398nOWdjaozyfIcmeXhznW84SaYnqSTbjvdcupXk7cCzVfXNVtuMJJ9L8kSSZ5qft08k2Xss5lBV36+qF1TV6o2tlWRhkvcOaKskP25+vn+Y5LNJdtnYc40wj4eSvHnt4015jcDFwHFJ9twEtaRxZ0CWJrjmF+ALquoFwPeBt7fa/nETnebHwNuBKcDxwF8m+WWAJNsDXwL+AdgVuAT4UtM+lI+2511Vl2+ieW6QXgqXbb06b+B3gEvXPkiyL3Ab8Cjw6qp6ITAH+HfgkMEK9Mi1v6r5d/nzdP5tnDm+09lwVfUT4KvAu0fqK/UCA7K0lUqyQ5ILkjza3C5IskNz7NAkDyf5X83q1kPDrTZX1RlV9Z2qWlNVtwE3Ab/UHD4U2Ba4oKpWVNVfAQHeNMr5bpPklCT/nuTJJP+UZLfW8SuS/GeSpUm+keQVTftJwLHAHzWrdf/ctFcTvNaO/+kqc+v6/zjJfwKfHun8I8x9YZJzkvzr2jkk2T3JPzaroXckmd7qX82frB9snv+PJdmm9TycnuQ/kjye5DNJpjTH1q4WvyfJ94F/Ab7RlH26OfcvJfmFJP/SXMcPm3ns0jr/Q0lOTnJ383xenuRnWsffkeSuZu7/nuQtTfuUJJ9K8liSR5prntQc2zfJjU29HyYZ9D96mv9wehNwY6v5TOCWqvrDqnoYoKoer6oLqupzw7xmuyb5cjqrzk819/duneulzZyeTXIdsEfr2Dor7yNc2wlJbk7nLylPJflekrc2x84FXgdc2Dz/Fw685qp6BrgaOKB1/hcnuTrJj5I8kOS3W8eG+7e7R3OdTzdjb2p+Zi4FXgL8czOPPxrkGhcm+Ug621ueTXJtkvZz8u7m5+7JJP87A1akgYXA4YO9rlKvMSBLW6/TgNcCM4FXAbOB01vHX0QnMOxFZ1X44iQvG6loksnALwLfbppeAdxd636v/d1N+2h8EJgHvAF4MfAU8Net418FZgB7AncC/whQVRc399euSr+9y/O9CNgN2Ac4qYvzj+QY4DfpPJ+/ANwKfLo5x73AGQP6Hwn0Aa8B3gH8VtN+QnN7I52VxxcAA0PXG4D9gV8FXt+07dJc/610/gPlT5vr2B+Yxvqrl+8E3gK8FDioOSdJZgOfAT4M7NLUf6gZcwmwCtgXeDXwK8DarQUfAa6ls1K6N/CJQZ4j6LyGa9YG4cabgc8P0b9t4Gu2DZ3neB864fC/Wfe5ugxYTOfn/CN0fs6HMty1ARwM3NfU+ijwqSSpqtPo/AfjB5rn/wMDCyfZlc7P1qJW82eBh+m8RkcB/yfJYc2x4f7t/s9m3M8CPwf8L6Cq6jdZ9y9IHx3iOn8DOJHOv6PtgZObOR4A/A2d/9icSuevRXsNGHtvMx+p91WVN2/etpIbnSDz5ub+vwNvax37VeCh5v6hdMLATq3j/wT87y7OcQmwAEjz+H8DnxvQ5x+BM4cY//fAT4Cnm9sPm/Z7gcNa/aYCK4FtB6mxC1DAlFbNcwb0KWDfAec9p3X9zwE/0zo+mvMfCjzcerwQOK31+M+Br7Yevx24a8Dc3tJ6/D7ghub+DcD7WsdetnYewPRm7M+3jq9tW2+erT7zgG8O+Dk5rvX4o8DfNfcvAj4+SI2fA1YAk1tt7wK+3tz/DJ19qnuP8PMzB/jPAW2rBjwfH2h+NpYB/3eo12yQ2jOBp5r7L2H9n/HLgH8Y+Lx1cW0nAA+0ju3YjH1R6/V/7yA/f88017Ea+A6wV3NsWtO2c6v/nwJ/38W/3bPpbGnad5Drf4jm3/9gPxvNPE8f8HO3oLn/J8BnB1zjcwPqzQBWD/f6evPWKzdXkKWt14uB/2g9/o+mba2nqurHwxxfT5KPAa8E3llVa1eMlwEvHND1hcCzw5T6s6rapbmt/RPvPsAXmj8dP00nsK4Gfi7JpCTnNX/uf4bnVzT3WK9y956ozr7KtYY8f5f1/qt1/78HefyCAf1/0Lrffu4He93WhrjBxq4nyZ7pvOHtkeb5+gfWf67+s3V/eWt+0+gEtIH2AbYDHms9RxfRWYkE+CM6K9e3J/l2kt8apAZ0VuZ3HtD2JJ3/IAGgqi6sql2AC5pzrrXOa5ZkxyQXNdsCnqGz3WSXZmvEixn8Z3wwI10btJ6vqlre3B34mg70muY6fgb4W+CmZivLi4EfVVX738h/8PyK7XD/dj8GPABcm84WnVNGmMNAQ73uL6b1c9Vc45MDxu4MLB3l+aQtkgFZ2no9SucX/1ovadrW2jXJTsMcX0eSs4C3Ar9SnT2Va30bOChJWm0H8fwWjG79AHhrKzjvUlU/U1WP0Pmz8Dvo/Cl+Cp2VMegEMuiskg20nM4q2FovGnB84Jjhzj8WprXut5/7wV63VawbuGuI+2v9adN+UHXe8HYczz9XI/kBnS0ig7WvAPZoPT8vrKpXAFTVf1bVb1fVi4H/D/ibtPaAt3wXSJL2n+9vAP5HF3MbeK3/k84K+8HNda7dbhLgMQb/GR/MsNe2AfNa92DVSuCTdLazvJLOa7xbkvZ/KLwEWPuzNuS/3ap6tqr+Z1X9PJ2/TPxha2vGsPMYwWN0tsYAP91KtfuAPvsD39qIc0hbDAOytPX6LHB6kp9t3ojzJ3RWEtvOSrJ9ktcBvwZcMVihJKfSCalzq2rgqtJCOiutH2zeXLR2D+a/jHK+fwecm2Sf5pw/m+QdzbGd6QSYJ+mE3v8zYOx/0dmv23YX8BvN6vNb6Ozb3dDzj4UPp/Mms2nA7wNr39T2WeBD6bzB7AV0rvXyqlo1RJ0ngDWse/0701nZf7oJoh8exbw+BZyY5LDmzV97JXl5VT1GZ4/xnyd5YXPsF5K8ASDJ/Dz/Brmn6IS19T5erAmL17Pu63Em8Lokf7E2ODc/s/uPMNed6azOP53OGyp/us+7qv4D6Of5n/FD6ATK9Yx0bV0Y7Ofvp5oV7RObuT5YVT8A/hX40yQ/k+Qg4D00++oZ5t9ukl9L5w2RobOFYzXPP8/DzmMEVwJvT/LL6byR8izW/4+qN9B5L4DU8wzI0tbrHDoB4W5gCZ03trU/K/g/6QSZR+n8Yv6dqvrOELX+D51VrO/m+c8u/l8AVfUcnT2u76az3/K3gHlN+2j8JZ13+l+b5Fk6b2g6uDn2GTp/Zn4EuId13+wEnVB3QPPn8S82bb9PJxA9TeeNR19keMOdfyx8ic4byO4CrqFzDQD/j85HoH0D+B6d/dq/N1SR5k/h5wK3NNf/Wjrh5jV0/hx+DXBVt5OqqtvphLmPN+Nv5PnVzHfTeWPXPXR+dq7k+a0RvwjclmQZnefx96vqe0Oc5iI6b2hce8776bwpbW/gW83zfwudn83/Pcx0LwAmAz+k83otGHD8N+i8hj+iE54/M0yt4a5tJH8JHJXOJ1z8Vav9W83z8RSdNwgeWVU/ao69i85fQh4FvgCcUVXXNceG+7c7g85/YCyj80bQv6mqhc2xP6UTrJ9OcnKXcwegqr5N5+fsc3RWk58FHqfzH6Y0W0PeRuc9CFLPW/smGkn6qSSH0nmz0ph8CYOGl6SAGVX1wHjPZbwkuRn4vWp9WYi2HM1fL56m83P6vSS/B0yrqj8a35lJm0YvfJC6JGkrU1WDfgGIxk8633B4A52tFX9GZ/X6IYCqGupj+6Se5BYLSZLUjXfQ2fLxKJ2tHMeUf4bWBOUWC0mSJKnFFWRJkiSpxT3IG2GPPfao6dOnj/c0JEmStAEWL178w6r62YHtBuSNMH36dPr7+8d7GpIkSdoASQb9Bk23WEiSJEktBmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJajEgS5IkSS0GZEmSJKnFgCxJkiS1GJAlSZKkFgOyJEmS1GJAliRJkloMyJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWrYd7wn0siWPLGX6KdeM9zTGxUPnHT7eU5AkSRoTriBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWsY0ICc5IcmFYzU+yceT3NXc7k/y9IDjL0zySLtGkpcmuS3Jd5NcnmT7pv3QJEtb9f5kQ+ctSZKk3tXTn4NcVR9aez/J7wGvHtDlI8CNA9rOBz5eVZ9L8nfAe4C/bY7dVFW/NlbzlSRJ0pavqxXkJMclub1ZWb0oyaQky5Kcn2RxkuuTzE6yMMmDSY5oDZ+WZEGS+5KcMVzNpv3EZjX4RmDOKK7lXcBnW/VnAT8HXNtqC/Am4Mqm6RJg3ijOIUmSpAluxICcZH/gaGBOVc0EVgPHAjsBC6tqFvAscA4wFzgSOLtVYnbTfyYwP0nfUDWTTAXOohOM5wIHdHMRSfYBXgr8S/N4G+DPgQ8P6Lo78HRVrWoePwzs1Tr+S0m+leSrSV4xxLlOStKfpH/18qXdTE+SJEk9pJstFocBs4A7OguwTAYeB54DFjR9lgArqmplkiXA9Nb466rqSYAkVwGHAKuGqHkwndD9RNP/cmC/LuZ4DHBlVa1uHr8P+EpV/aCpv1bWGwnV/O+dwD5VtSzJ24AvAjPW61x1MXAxwA5TZ9TA45IkSept3QTkAJdU1anrNCYnV9XagLgGWAFQVWuStOsODJE1TM15g/TvxjHA+1uPfwl4XZL3AS8Atk+yDDgV2CXJts0q8t7Ao828n/npBKu+kuRvkuxRVT/cgPlIkiSpR3WzB/kG4KgkewIk2a3Z0tCtuc2YyXT2+94yTM3bgEOT7J5kO2D+SMWTvAzYFbh1bVtVHVtVL6mq6cDJwGeq6pQm0H8dOKrpejzwpabOi5o9yiSZTee5eXIU1ylJkqQJYMQV5Kq6J8npwLXN3t6VrLtaO5KbgUuBfYHLqqofYLCaVbUoyZl0wu5jdLY9TBqh/ruAz7VWs0fyx8DnkpwDfBP4VNN+FPC7SVYB/w0cM4qakiRJmiBiBtxwO0ydUVOPv2C8pzEuHjrv8PGegiRJ0kZJsriq+ga2+016kiRJUktPfFFIktNYfz/yFVV17njMR5IkSRNXTwTkJggbhiVJkjTmeiIgb6kO3GsK/e7FlSRJmlDcgyxJkiS1GJAlSZKkFgOyJEmS1GJAliRJklp8k95GWPLIUqafcs14T2OL5heKSJKkXuMKsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJajEgS5IkSS0GZEmSJKllTANykhOSXDjW45MclaSS9LXazk/yb83t6Fb7p5J8K8ndSa5M8oKmPUn+KskDzbHXbOi8JUmS1Lt6fgU5yc7AB4HbWm2HA68BZgIHAx9O8sLm8Ieq6lVVdRDwfeADTftbgRnN7STgbzfLBUiSJGmL0lVATnJcktuT3JXkoiSTkixrVmkXJ7k+yewkC5M8mOSI1vBpSRYkuS/JGcPVbNpPTHJ/khuBOV1M7yPAR4GftNoOAG6sqlVV9WPgW8BbAKrqmeY8ASYD1Yx5B/CZ6lgE7JJkajfPjyRJkiaOEQNykv2Bo4E5VTUTWA0cC+wELKyqWcCzwDnAXOBI4OxWidlN/5nA/CR9Q9VsAulZdILxXDpBd7i5vRqYVlVfHnDoW8Bbk+yYZA/gjcC01rhPA/8JvBz4RNO8F/CDVo2Hm7aB5zwpSX+S/tXLlw43PUmSJPWgbr5q+jBgFnBHZ9GVycDjwHPAgqbPEmBFVa1MsgSY3hp/XVU9CZDkKuAQYNUQNQ+mE7qfaPpfDuw32KSSbAN8HDhh4LGqujbJLwL/CjwB3Nqcc+3xE5sV60/QCeqfBjLIaWq9hqqLgYsBdpg6Y73jkiRJ6m3dbLEIcElVzWxuL6uqM4GVVbU2IK4BVgBU1RrWDd4DQ2QNU3Ow/kPZGXglsDDJQ8BrgavXvlGvqs5tas9tzvfddSZRtRq4HPj1pulhWqvMwN7Ao13ORZIkSRNENwH5BuCoJHsCJNktyT6jOMfcZsxkYB5wyzA1bwMOTbJ7ku2A+UMVraqlVbVHVU2vqunAIuCIqupv9kjv3tQ+CDgIuLb5pIp9m/YAbwe+05S8Gnh30+e1wNKqemwU1ylJkqQJYMQtFlV1T5LT6QTMbYCVwPtHcY6bgUuBfYHLqqofYLCaVbUoyZl0tkQ8BtwJTBrFudbaDrip2b7xDHBcVa1qznVJ84kWobNX+XebMV8B3gY8ACwHTtyA80qSJKnH5fldEhqtHabOqKnHXzDe09iiPXTe4eM9BUmSpEElWVxVfQPbe/5zkCVJkqRNqZtPsRh3SU5j/f3IV1TVueMxH0mSJE1cPRGQmyBsGJYkSdKY64mAvKU6cK8p9LvHVpIkaUJxD7IkSZLUYkCWJEmSWgzIkiRJUosBWZIkSWrxTXobYckjS5l+yjXjPY2e4heHSJKkLZ0ryJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqSWMQ3ISU5IcuFYj09yVJJK0tdqe0mSa5Pcm+SeJNOb9g8keaDpv8cgtX4xyeokR23ovCVJktS7en4FOcnOwAeB2wYc+gzwsaraH5gNPN603wK8GfiPQWpNAs4HvjZmE5YkSdIWrauAnOS4JLcnuSvJRUkmJVmW5Pwki5Ncn2R2koVJHkxyRGv4tCQLktyX5IzhajbtJya5P8mNwJwupvcR4KPAT1q1DwC2rarrAKpqWVUtb+5/s6oeGqLW7wGf5/kwLUmSpK3MiAE5yf7A0cCcqpoJrAaOBXYCFlbVLOBZ4BxgLnAkcHarxOym/0xgfpK+oWommQqcRScYzwUOGGFurwamVdWXBxzaD3g6yVVJvpnkY2sD+DC19mrm/ncj9DspSX+S/tXLlw7XVZIkST2om6+aPgyYBdyRBGAynRXW54AFTZ8lwIqqWplkCTC9Nf66qnoSIMlVwCHAqiFqHkwndD/R9L+cTthdT5JtgI8DJwxxXa8DXg18H7i86fepYa7zAuCPq2p1M6dBVdXFwMUAO0ydUcPUkyRJUg/qJiAHuKSqTl2nMTm5qtYGxDXACoCqWpOkXXdgiKxhas4bpP9QdgZeCSxsAu2LgKub7R0PA9+sqgebul8EXsvwAbkP+FxTaw/gbUlWVdUXu5yPJEmSJoBu9iDfAByVZE+AJLsl2WcU55jbjJkMzKPzJrmhat4GHJpk9yTbAfOHKlpVS6tqj6qaXlXTgUXAEVXVD9wB7JrkZ5vubwLuGW6SVfXSVq0rgfcZjiVJkrY+IwbkqroHOB24NsndwHXA1FGc42bgUuAu4PNV1T9Uzap6DDgTuBW4HrhzFOdpz3k1cDJwQ7PlI8D/BUjywSQPA3sDdyf55IacQ5IkSRNTnt8lodHaYeqMmnr8BeM9jZ7y0HmHj/cUJEmSAEiyuKr6Brb3/OcgS5IkSZtSN2/SG3dJTmP9/chXVNW54zEfSZIkTVw9EZCbIGwYliRJ0pjriYC8pTpwryn0u6dWkiRpQnEPsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJavFNehthySNLmX7KNeM9jZ7jl4VIkqQtmSvIkiRJUosBWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktRiQJUmSpJYxDchJTkhy4ViPT3JUkkrS12r7aJJvJ7k3yV8lSdP+0iS3JfluksuTbN8ac2iSu5pxN27ovCVJktS7en4FOcnOwAeB21ptvwzMAQ4CXgn8IvCG5vD5wMeragbwFPCeZswuwN8AR1TVK4D5m+kSJEmStAXpKiAnOS7J7c3q6kVJJiVZluT8JIuTXJ9kdpKFSR5MckRr+LQkC5Lcl+SM4Wo27Scmub9ZwZ3TxfQ+AnwU+EmrrYCfAbYHdgC2A/6rWUV+E3Bl0+8SYF5z/zeAq6rq+wBV9fgQz8VJSfqT9K9evrSL6UmSJKmXjBiQk+wPHA3MqaqZwGrgWGAnYGFVzQKeBc4B5gJHAme3Ssxu+s8E5ifpG6pmkqnAWXSC8VzggBHm9mpgWlV9ud1eVbcCXwcea25fq6p7gd2Bp6tqVdP1YWCv5v5+wK5NyF+c5N2DnbOqLq6qvqrqm7TjlOGmJ0mSpB7UzVdNHwbMAu5otvFOBh4HngMWNH2WACuqamWSJcD01vjrqupJgCRXAYcAq4aoeTCd0P1E0/9yOsF1PUm2AT4OnDDIsX2B/YG9184hyeuBewcpVc3/btvM6bBmPrcmWVRV9w/xvEiSJGkC6iYgB7ikqk5dpzE5uarWhss1wAqAqlqTpF23WFcNU3PeIP2HsjOd/cULm5D9IuDqZnvHG4FFVbWsqftV4LXATcAuSbZtVpH3Bh5t6j0M/LCqfgz8OMk3gFcBBmRJkqStSDd7kG8AjkqyJ0CS3ZLsM4pzzG3GTKaz3/eWYWreBhyaZPck2zHMG+WqamlV7VFV06tqOrCIzhvs+oHvA29Ism1T5w3AvU2g/zpwVFPmeOBLzf0vAa9rxuxIZzV7sBVnSZIkTWAjriBX1T1JTgeubbY1rATeP4pz3AxcCuwLXNYEWAarWVWLkpwJ3Epn7/CdwKRRnGutK+m8GW8JnRXpBVX1z82xPwY+l+Qc4JvAp5rrvDfJAuBuOivin6yqf9uAc0uSJKmH5fldEhqtHabOqKnHXzDe0+g5D513+HhPQZIkiSSLq6pvYHvPfw6yJEmStCl18ya9cZfkNNbfj3xFVZ07HvORJEnSxNUTAbkJwoZhSZIkjbmeCMhbqgP3mkK/+2klSZImFPcgS5IkSS0GZEmSJKnFgCxJkiS1GJAlSZKkFt+ktxGWPLKU6adcM97TmPD8YhFJkrQ5uYIsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJahnTgJzkhCQXjtX4JH+Y5J4kdye5Ick+TfvMJLcm+XZz7OhBxn4iybLW4ylJ/jnJt5pxJ27ovCVJktS7en0F+ZtAX1UdBFwJfLRpXw68u6peAbwFuCDJLmsHJekDdlm3FO8H7qmqVwGHAn+eZPsxnb0kSZK2OF0F5CTHJbk9yV1JLkoyKcmyJOcnWZzk+iSzkyxM8mCSI1rDpyVZkOS+JGcMV7NpPzHJ/UluBOYMN6+q+npVLW8eLgL2btrvr6rvNvcfBR4HfrapPwn4GPBHA8sBOycJ8ALgR8CqQZ6Lk5L0J+lfvXxpN0+fJEmSesiIATnJ/sDRwJyqmgmsBo4FdgIWVtUs4FngHGAucCRwdqvE7Kb/TGB+kr6haiaZCpxFJxjPBQ4YxbW8B/jqIPOfDWwP/HvT9AHg6qp6bEDXC4H9gUeBJcDvV9WagfWq6uKq6quqvkk7ThnF9CRJktQLuvmq6cOAWcAdncVVJtNZkX0OWND0WQKsqKqVSZYA01vjr6uqJwGSXAUcQmdldrCaB9MJ3U80/S8H9htpgkmOA/qANwxonwpcChxfVWuSvBiYT2cLxUC/CtwFvAn4BeC6JDdV1TMjnV+SJEkTRzcBOcAlVXXqOo3JyVVVzcM1wAqAJoi26xbrqmFqzhuk//CTS94MnAa8oapWtNpfCFwDnF5Vi5rmVwP7Ag80wXzHJA9U1b7AicB5zTU9kOR7wMuB20czH0mSJPW2bvYg3wAclWRPgCS7rf20iC7NbcZMBuYBtwxT8zbg0CS7J9mOzmrvkJK8GrgIOKKqHm+1bw98AfhMVV2xtr2qrqmqF1XV9KqaDixvwjHA9+mslpPk54CXAQ+O4jolSZI0AYy4glxV9yQ5Hbg2yTbASjqf+NCtm+lsc9gXuKyq+gEGq1lVi5KcCdwKPAbcCUwapvbH6Lyh7opmRfj7VXUE8E7g9cDuSU5o+p5QVXcNU+sjwN83W0QC/HFV/XAU1ylJkqQJIM/vktBo7TB1Rk09/oLxnsaE99B5h4/3FCRJ0gSUZHFV9Q1s7/XPQZYkSZI2qW7epDfukpzG+vuRr6iqc8djPpIkSZq4eiIgN0HYMCxJkqQx1xMBeUt14F5T6Hd/rCRJ0oTiHmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktTim/Q2wpJHljL9lGvGexpbJb88RJIkjRVXkCVJkqQWA7IkSZLUYkCWJEmSWgzIkiRJUosBWZIkSWoxIEuSJEktYxqQk5yQ5MKxGp/k40nuam73J3m6ad8nyeKm/dtJfqc15rAkdzbHbk6yb9O+a5IvJLk7ye1JXrmh85YkSVLv6unPQa6qD629n+T3gFc3Dx8DfrmqViR5AfBvSa6uqkeBvwXeUVX3JnkfcDpwAvC/gLuq6sgkLwf+GjhsM16OJEmStgBdrSAnOa5ZVb0ryUVJJiVZluT8ZqX2+iSzkyxM8mCSI1rDpyVZkOS+JGcMV7NpP7FZDb4RmDOKa3kX8FmAqnquqlY07TsMuM4CXtjcnwI82tw/ALihGf8dYHqSnxvkuTgpSX+S/tXLl45iepIkSeoFIwbkJPsDRwNzqmomsBo4FtgJWFhVs4BngXOAucCRwNmtErOb/jOB+Un6hqqZZCpwFp1gPJdOaB1Rkn2AlwL/0mqbluRu4AfA+c3qMcB7ga8keRj4TeC8pv1bwP9oxs4G9gH2Hniuqrq4qvqqqm/SjlO6mZ4kSZJ6SDdbLA4DZgF3JAGYDDwOPAcsaPosAVZU1cokS4DprfHXVdWTAEmuAg4BVg1R82A6ofuJpv/lwH5dzPEY4MqqWr22oap+AByU5MXAF5NcWVX/BXwIeFtV3Zbkw8Bf0AnN5wF/meSu5nq+2cxTkiRJW5FuAnKAS6rq1HUak5OrqpqHa4AVAFW1Jkm7brGuGqbmvEH6d+MY4P2DHaiqR5N8G3hds23jVVV1W3P4cpqQX1XPACc28wjwveYmSZKkrUg3e5BvAI5KsidAkt2aLQ3dmtuMmQzMA24ZpuZtwKFJdk+yHTB/pOJJXgbsCtzaatu7OR9JdqWzZeM+4ClgSpK1q9JzgXubfrsk2b5pfy/wjSY0S5IkaSsy4gpyVd2T5HTg2iTbACsZYrV2CDcDlwL7ApdVVT/AYDWralGSM+mE3ceAO4FJI9R/F/C51mo2wP7AnydZu1r9Z1W1pDnvbwOfT7KGTmD+rdaYzyRZDdwDvGcU1yhJkqQJIuvmSo3GDlNn1NTjLxjvaWyVHjrv8PGegiRJ6nFJFldV38B2v0lPkiRJaumJLwpJchrr70e+oqrOHY/5SJIkaeLqiYDcBGHDsCRJksZcTwTkLdWBe02h372wkiRJE4p7kCVJkqQWA7IkSZLUYkCWJEmSWgzIkiRJUotv0tsISx5ZyvRTrhnvaWy1/LIQSZI0FlxBliRJkloMyJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqcWALEmSJLWMaUBOckKSC8dqfJKPJ7mrud2f5Omm/Y2t9ruS/CTJvObYTa32R5N8sWl/R5K7m/b+JIds6LwlSZLUu3r6c5Cr6kNr7yf5PeDVTfvXgZlN+27AA8C1zbHXtcZ8HvhS8/AG4OqqqiQHAf8EvHzsr0KSJElbkq5WkJMcl+T2ZnX1oiSTkixLcn6SxUmuTzI7ycIkDyY5ojV8WpIFSe5LcsZwNZv2E5vV4BuBOaO4lncBnx2k/Sjgq1W1fMA17Qy8CfgiQFUtq6pqDu8EFINIclKzwty/evnSUUxPkiRJvWDEgJxkf+BoYE5VzQRWA8fSCZELq2oW8CxwDjAXOBI4u1VidtN/JjA/Sd9QNZNMBc6iE4znAgd0cxFJ9gFeCvzLIIePYfDgfCRwQ1U906pzZJLvANcAvzXYuarq4qrqq6q+STtO6WZ6kiRJ6iHdbLE4DJgF3JEEYDLwOPAcsKDpswRYUVUrkywBprfGX1dVTwIkuQo4BFg1RM2D6YTuJ5r+lwP7dTHHY4Arq2p1u7EJ3AcCXxtkzLuAT7YbquoLwBeSvB74CPDmLs4tSZKkCaSbgBzgkqo6dZ3G5OTWloQ1wAqAqlqTpF134FaFGqbmvEH6d+MY4P2DtL8T+EJVrRxwnt3prGwfOVixqvpGkl9IskdV/XAD5iNJkqQe1c0e5BuAo5LsCZ03vTVbGro1txkzGZgH3DJMzduAQ5PsnmQ7YP5IxZO8DNgVuHWQw0PtS54PfLmqftKqs2+a5ewkrwG2B57s/jIlSZI0EYy4glxV9yQ5Hbg2yTbASgZfrR3KzcClwL7AZVXVDzBYzapalORMOmH3MeBOYNII9d8FfK61mk1TfzowDbhxkDHHAOcNaPt14N1JVgL/DRw9sKYkSZImvpgBN9wOU2fU1OMvGO9pbLUeOu/w8Z6CJEnqYUkWV1XfwHa/SU+SJElq6YkvCklyGuvvR76iqs4dj/lIkiRp4uqJgNwEYcOwJEmSxlxPBOQt1YF7TaHffbCSJEkTinuQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSi2/S2whLHlnK9FOuGe9paAP5RSOSJGkwriBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWsY0ICc5IcmFYzU+yeuT3JlkVZKjBhw7P8m/NbejW+03JbmruT2a5ItN+zuS3N209yc5ZEPnLUmSpN7V65+D/H3gBODkdmOSw4HXADOBHYAbk3y1qp6pqte1+n0e+FLz8Abg6qqqJAcB/wS8fMyvQJIkSVuUrlaQkxyX5PZmdfWiJJOSLGtWaRcnuT7J7CQLkzyY5IjW8GlJFiS5L8kZw9Vs2k9Mcn+SG4E5w82rqh6qqruBNQMOHQDcWFWrqurHwLeAtwy4pp2BNwFfbGotq6pqDu8EFINIclKzwty/evnS4Z84SZIk9ZwRA3KS/YGjgTlVNRNYDRxLJ0QurKpZwLPAOcBc4Ejg7FaJ2U3/mcD8JH1D1UwyFTiLTjCeSyfobohvAW9NsmOSPYA3AtMG9DkSuKGqnmld65FJvgNcA/zWYIWr6uKq6quqvkk7TtnA6UmSJGlL1c0Wi8OAWcAdSQAmA48DzwELmj5LgBVVtTLJEmB6a/x1VfUkQJKrgEOAVUPUPJhO6H6i6X85sN9oL6qqrk3yi8C/Ak8AtzbnbHsX8MkB474AfCHJ64GPAG8e7bklSZLU27rZYhHgkqqa2dxeVlVnAitbWxLWACsAqmoN6wbvgVsVapiag/XfIFV1blN7bnO+7/70gpLd6axsXzPE2G8Av9CsPkuSJGkr0k1AvgE4KsmeAEl2S7LPKM4xtxkzGZgH3DJMzduAQ5PsnmQ7YP4ozvNTzR7p3Zv7BwEHAde2uswHvlxVP2mN2TfNcnaS1wDbA09uyPklSZLUu0bcYlFV9yQ5Hbg2yTbASuD9ozjHzcClwL7AZVXVDzBYzapalORMOlsiHgPuBCYNVbjZRvEFYFfg7UnOqqpXANsBNzV59xnguKpqb7E4BjhvQLlfB96dZCXw38DRrRVySZIkbSViBtxwO0ydUVOPv2C8p6EN9NB5h4/3FCRJ0jhKsriq+ga2+016kiRJUktPfFFIktNYfz/yFVV17njMR5IkSRNXTwTkJggbhiVJkjTmeiIgb6kO3GsK/e5jlSRJmlDcgyxJkiS1GJAlSZKkFgOyJEmS1GJAliRJklp8k95GWPLIUqafcs14T0ObkF8eIkmSXEGWJEmSWgzIkiRJUosBWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktYxpQE5yQpILx2p8ko8nuau53Z/k6QHHX5jkkcFqJPlEkmWtxy9PcmuSFUlO3tA5S5Ikqbf19OcgV9WH1t5P8nvAqwd0+Qhw48BxSfqAXQY0/wj4IDBvk05SkiRJPaWrFeQkxyW5vVmpvSjJpCTLkpyfZHGS65PMTrIwyYNJjmgNn5ZkQZL7kpwxXM2m/cRmNfhGYM4oruVdwGdb9WcBPwdcO+BaJgEfA/6o3V5Vj1fVHcDKEZ6Lk5L0J+lfvXzpKKYnSZKkXjBiQE6yP3A0MKeqZgKrgWOBnYCFVTULeBY4B5gLHAmc3Soxu+k/E5ifpG+omkmmAmfRCcZzgQO6uYgk+wAvBf6lebwN8OfAhwfp/gHg6qp6rJvaA1XVxVXVV1V9k3acsiElJEmStAXrZovFYcAs4I4kAJOBx4HngAVNnyXAiqpamWQJML01/rqqehIgyVXAIcCqIWoeTCd0P9H0vxzYr4s5HgNcWVWrm8fvA75SVT9o6tPUezEwHzi0i5qSJEnaCnUTkANcUlWnrtOYnFxV1TxcA6wAqKo1Sdp1i3XVMDXnDdK/G8cA7289/iXgdUneB7wA2L55Q95NwL7AA01w3jHJA1W17wacU5IkSRNQNwH5BuBLST5eVY8n2Q3YeRTnmNuM+W86b4D7LWD5EDVvA/4yye7AM3RWe781XPEkLwN2BW5d21ZVx7aOnwD0VdUpTdOLWseWGY4lSZLUNmJArqp7kpwOXNvs7V3Juqu1I7kZuJTOyu1lVdUPMFjNqlqU5Ew6Yfcx4E5g0gj13wV8rrWavUGSvAjoB14IrEnyB8ABVfXMxtSVJElSb8lG5sqt2g5TZ9TU4y8Y72loE3rovMPHewqSJGkzSbK4qvoGtvtNepIkSVJLT3xRSJLT6OxHbruiqs4dj/lIkiRp4uqJgNwEYcOwJEmSxlxPBOQt1YF7TaHfPauSJEkTinuQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSi2/S2whLHlnK9FOuGe9paBPzy0IkSdq6uYIsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJahnTgJzkhCQXjtX4JL+TZEmSu5LcnOSApv2NTdva20+SzGuOfSDJA0kqyR6tWu9IcnfTvz/JIRs6b0mSJPWuXv8c5Muq6u8AkhwB/AXwlqr6OjCzad8NeAC4thlzC/BlYOGAWjcAV1dVJTkI+Cfg5WN9AZIkSdqydLWCnOS4JLc3q6sXJZmUZFmS85MsTnJ9ktlJFiZ5sAmra01LsiDJfUnOGK5m035ikvuT3AjMGW5eVfVM6+FOQA3S7Sjgq1W1vBnzzap6aJBay6pq7fihapHkpGaFuX/18qXDTU+SJEk9aMSAnGR/4GhgTlXNBFYDx9IJkQurahbwLHAOMBc4Eji7VWJ2038mMD9J31A1k0wFzqITjOcCB3Qxv/cn+Xfgo8AHB+lyDPDZkeo0tY5M8h3gGuC3ButTVRdXVV9V9U3acUo3ZSVJktRDutlicRgwC7gjCcBk4HHgOWBB02cJsKKqViZZAkxvjb+uqp4ESHIVcAiwaoiaB9MJ3U80/S8H9htuclX118BfJ/kN4HTg+LXHmsB9IPC1Lq6TqvoC8IUkrwc+Ary5m3GSJEmaOLoJyAEuqapT12lMTm5tSVgDrACoqjVJ2nUHblWoYWrOG6R/tz4H/O2AtncCX6iqlaMpVFXfSPILSfaoqh9u4HwkSZLUg7rZg3wDcFSSPaHzprck+4ziHHObMZOBeXTeJDdUzduAQ5PsnmQ7YP5whZPMaD08HPjugC7vovvtFfumWc5O8hpge+DJbsZKkiRp4hhxBbmq7klyOnBtkm2AlcD7R3GOm4FLgX3pfOpEP8BgNatqUZIzgVuBx4A7gUnD1P5Akjc3459i3e0V04FpwI3tAUk+CPwR8CLg7iRfqar3Ar8OvDvJSuC/gaNbK+SSJEnaSsQMuOF2mDqjph5/wXhPQ5vYQ+cdPt5TkCRJm0GSxVXVN7Ddb9KTJEmSWnrii0KSnMb6+5GvqKpzx2M+kiRJmrh6IiA3QdgwLEmSpDHXEwF5S3XgXlPod7+qJEnShOIeZEmSJKnFgCxJkiS1GJAlSZKkFvcgb4Qljyxl+inXjPc0tAXzM5UlSeo9riBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWgzIkiRJUsuYBuQkJyS5cKzGJ3l9kjuTrEpy1IBjC5I8neTLA9o/kOSBJJVkj1b7lCT/nORbSb6d5MQNnbckSZJ6V6+vIH8fOAG4bJBjHwN+c5D2W4A3A/8xoP39wD1V9SrgUODPk2y/yWYqSZKkntBVQE5yXJLbk9yV5KIkk5IsS3J+ksVJrk8yO8nCJA8mOaI1fFqzmntfkjOGq9m0n5jk/iQ3AnOGm1dVPVRVdwNrBjl2A/DsIO3frKqHBisH7JwkwAuAHwGrBnkuTkrSn6R/9fKlw01PkiRJPWjEgJxkf+BoYE5VzQRWA8cCOwELq2oWnSB6DjAXOBI4u1VidtN/JjA/Sd9QNZNMBc6iE4znAgds/CV27UJgf+BRYAnw+1U1WPC+uKr6qqpv0o5TNuP0JEmStDls20Wfw4BZwB2dxVUmA48DzwELmj5LgBVVtTLJEmB6a/x1VfUkQJKrgEPorMwOVvNgOqH7iab/5cB+G3F9o/GrwF3Am4BfAK5LclNVPbOZzi9JkqQtQDcBOcAlVXXqOo3JyVVVzcM1wAqAqlqTpF23WFcNU3PeIP03lxOB85preiDJ94CXA7eP03wkSZI0DrrZg3wDcFSSPQGS7JZkn1GcY24zZjIwj86b5IaqeRtwaJLdk2wHzB/FeTbW9+mslpPk54CXAQ9uxvNLkiRpCzBiQK6qe4DTgWuT3A1cB0wdxTluBi6ls33h81XVP1TNqnoMOBO4FbgeuHO4wkl+McnDdIL0RUm+3Tp2E3AFcFiSh5P8atP+wWbM3sDdST7ZDPkI8MvNFpEbgD+uqh+O4jolSZI0AeT5XRIarR2mzqipx18w3tPQFuyh8w4f7ylIkqQhJFlcVX0D23v9c5AlSZKkTaqbN+mNuySnsf5+5Cuq6tzxmI8kSZImrp4IyE0QNgxLkiRpzPVEQN5SHbjXFPrdYypJkjShuAdZkiRJajEgS5IkSS0GZEmSJKnFPcgbYckjS5l+yjXjPQ31OD8rWZKkLYsryJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUMqYBOckJSS4cq/FJ/jDJPUnuTnJDkn0GHH9hkkcGq5HkE0mWtR4fmmRpkrua259s6LwlSZLUu3r9i0K+CfRV1fIkvwt8FDi6dfwjwI0DByXpA3YZpN5NVfVrYzFRSZIk9YauVpCTHJfk9mZl9aIkk5IsS3J+ksVJrk8yO8nCJA8mOaI1fFqSBUnuS3LGcDWb9hOT3J/kRmDOcPOqqq9X1fLm4SJg71b9WcDPAdcOuJZJwMeAP+rm2gd5Lk5K0p+kf/XypRtSQpIkSVuwEQNykv3prMrOqaqZwGrgWGAnYGFVzQKeBc4B5gJHAme3Ssxu+s8E5ifpG6pmkqnAWXSC8VzggFFcy3uArzZz3gb4c+DDg/T7AHB1VT02yLFfSvKtJF9N8orBTlJVF1dVX1X1TdpxyiimJ0mSpF7QzRaLw4BZwB1JACYDjwPPAQuaPkuAFVW1MskSYHpr/HVV9SRAkquAQ4BVQ9Q8mE7ofqLpfzmw30gTTHIc0Ae8oWl6H/CVqvpBU39tvxcD84FDBylzJ7BPVS1L8jbgi8CMkc4tSZKkiaWbgBzgkqo6dZ3G5OSqqubhGmAFQFWtSdKuW6yrhqk5b5D+w08ueTNwGvCGqlrRNP8S8Lok7wNeAGzfvCHvJmBf4IEmOO+Y5IGq2reqnvnpBKu+kuRvkuxRVT8czXwkSZLU27rZg3wDcFSSPQGS7Dbw0yJGMLcZMxmYB9wyTM3bgEOT7J5kOzqrvUNK8mrgIuCIqnp8bXtVHVtVL6mq6cDJwGeq6pSquqaqXlRV05tjy6tq36bWi9Kk5iSz6Tw3T47iOiVJkjQBjLiCXFX3JDkduLbZ27sSeP8oznEzcCmdldvLqqofYLCaVbUoyZnArcBjdLY9TBqm9sforBBf0WTb71fVEcP0H85RwO8mWQX8N3BMa4VckiRJW4mYATfcDlNn1NTjLxjvaajHPXTe4eM9BUmStkpJFldV38B2v0lPkiRJaumJLwpJchrr70e+oqrOHY/5SJIkaeLqiYDcBGHDsCRJksZcTwTkLdWBe02h3/2jkiRJE4p7kCVJkqQWA7IkSZLUYkCWJEmSWtyDvBGWPLKU6adcM97TkIbkZyxLkjR6riBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWgzIkiRJUsuYBuQkJyS5cKzHJzkqSSXpax6/McldrdtPksxrjv1jkvuS/FuS/5dku1adQ5v+305y44bOW5IkSb2r51eQk+wMfBC4bW1bVX29qmZW1UzgTcBy4Nrm8D8CLwcOBCYD723q7AL8DXBEVb0CmL+ZLkGSJElbkK4CcpLjktzerK5elGRSkmVJzk+yOMn1SWYnWZjkwSRHtIZPS7KgWbU9Y7iaTfuJSe5vVnDndDG9jwAfBX4yxPGjgK9W1XKAqvpKNYDbgb2bfr8BXFVV32/6PT7Ec3FSkv4k/auXL+1iepIkSeolIwbkJPsDRwNzmhXZ1cCxwE7AwqqaBTwLnAPMBY4Ezm6VmN30nwnMT9I3VM0kU4Gz6ATjucABI8zt1cC0qvryMN2OAT47yNjtgN8EFjRN+wG7NiF/cZJ3D1asqi6uqr6q6pu045ThpidJkqQetG0XfQ4DZgF3JIHOtoTHged4PlwuAVZU1cokS4DprfHXVdWTAEmuAg4BVg1R82A6ofuJpv/ldILrepJsA3wcOGGoiTeB+0Dga4Mc/hvgG1V1U/N422ZOhzXzuTXJoqq6f6j6kiRJmni6CcgBLqmqU9dpTE5utikArAFWAFTVmiTtusW6apia8wbpP5SdgVcCC5uQ/SLg6iRHVFV/0+edwBeqauWA85wB/Czw/7WaHwZ+WFU/Bn6c5BvAqwADsiRJ0lakmz3INwBHJdkTIMluSfYZxTnmNmMmA/OAW4apeRtwaJLdmy0QQ75RrqqWVtUeVTW9qqYDi+i8wa6/1e1dDNhekeS9wK8C76qqNa1DXwJel2TbJDvSWc2+dxTXKUmSpAlgxBXkqronyenAtc22hpXA+0dxjpuBS4F9gcvWBtjBalbVoiRnArcCjwF3ApNGca6fSjIdmAYM/Li2vwP+g84WCui8Me/sqro3yQLgbjor4p+sqn/bkHNLkiSpd+X5XRIarR2mzqipx18w3tOQhvTQeYeP9xQkSdpiJVlcVX0D23v+c5AlSZKkTambN+mNuySnsf5+5Cuq6tzxmI8kSZImrp4IyE0QNgxLkiRpzPVEQN5SHbjXFPrd4ylJkjShuAdZkiRJajEgS5IkSS0GZEmSJKnFPcgbYckjS5l+yjXjPQ1pk/AzkyVJ6nAFWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaxjQgJzkhyYVjNT7J65PcmWRVkqMGHFuQ5OkkXx7Qflgz5q4kNyfZt2k/Nsndze1fk7xqQ+ctSZKk3tXrK8jfB04ALhvk2MeA3xyk/W+BY6tqZjPu9Kb9e8Abquog4CPAxZt6spIkSdrydRWQkxyX5PZm1fWiJJOSLEtyfpLFSa5PMjvJwiQPJjmiNXxas5p7X5IzhqvZtJ+Y5P4kNwJzhptXVT1UVXcDawY5dgPw7GDDgBc296cAjzb9/7WqnmraFwF7D/FcnJSkP0n/6uVLh5ueJEmSetCIATnJ/sDRwJxm1XU1cCywE7CwqmbRCaLnAHOBI4GzWyVmN/1nAvOT9A1VM8lU4Cw6wXgucMDGX+J63gt8JcnDdFaYzxukz3uArw42uKourqq+quqbtOOUMZieJEmSxtO2XfQ5DJgF3JEEYDLwOPAcsKDpswRYUVUrkywBprfGX1dVTwIkuQo4BFg1RM2D6YTuJ5r+lwP7bcT1DeZDwNuq6rYkHwb+gk5opjnnG+kE5EM28XklSZLUA7oJyAEuqapT12lMTq6qah6uAVYAVNWaJO26xbpqmJrzBum/yST5WeBVVXVb03Q5z4d8khwEfBJ469pQL0mSpK1LN3uQbwCOSrInQJLdkuwzinPMbcZMBuYBtwxT8zbg0CS7J9kOmD+K83TjKWBKkrWr0nOBe5s5vAS4CvjNqrp/E59XkiRJPWLEFeSquifJ6cC1SbYBVgLvH8U5bgYuBfYFLquqfoDBalbVoiRnArcCjwF3ApOGKpzkF4EvALsCb09yVlW9ojl2E/By4AXNfuP3VNXXkvw28Pkka+gE5t9qyv0JsDvwN822j1VV1TeK65QkSdIEkOd3SWi0dpg6o6Yef8F4T0PaJB467/DxnoIkSZtVksWDLYj2+ucgS5IkSZtUN2/SG3dJTmP9/chXVNW54zEfSZIkTVxusdgIfX191d/fP97TkCRJ0gZwi4UkSZLUBQOyJEmS1GJAliRJkloMyJIkSVJLT3yKxZZqySNLmX7KNeM9Dakn+bnLkqQtlSvIkiRJUosBWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktQypgE5yQlJLhyr8c3xJ5Lc1dze2zp2fJLvNrfjW+0vTXJb0355ku2b9iT5qyQPJLk7yWs2dN6SJEnqXRNhBfnyqprZ3D4JkGQ34AzgYGA2cEaSXZv+5wMfr6oZwFPAe5r2twIzmttJwN9uxmuQJEnSFqKrgJzkuCS3N6u0FyWZlGRZkvOTLE5yfZLZSRYmeTDJEa3h05IsSHJfkjOGq9m0n5jk/iQ3AnM28Lp+Fbiuqn5UVU8B1wFvSRLgTcCVTb9LgHnN/XcAn6mORcAuSaYO8lyclKQ/Sf/q5Us3cHqSJEnaUo0YkJPsDxwNzKmqmcBq4FhgJ2BhVc0CngXOAeYCRwJnt0rMbvrPBOYn6RuqZhNIz6ITjOcCB3RxDb/ebIm4Msm0pm0v4AetPg83bbsDT1fVqgHtw41ZR1VdXFV9VdU3accpXUxPkiRJvWTbLvocBswC7ugswDIZeBx4DljQ9FkCrKiqlUmWANNb46+rqicBklwFHAKsGqLmwXRC9xNN/8uB/YaZ2z8Dn62qFUl+h86K8JuADNK3hmlnhGOSJEnaSnSzxSLAJa19vi+rqjOBlVW1NkCuAVYAVNUa1g3eA0Pm2qA6WM3B+g+pqp6sqhXNw/9LJ3RDZ/V3Wqvr3sCjwA/pbJ3YdkD7cGMkSZK0FekmIN8AHJVkT+i8AS7JPqM4x9xmzGQ6+31vGabmbcChSXZPsh0wf7jCA/YIHwHc29z/GvArSXZt3pz3K8DXmkD/deCopt/xwJea+1cD724+zeK1wNKqemwU1ylJkqQJYMQtFlV1T5LTgWuTbAOsBN4/inPcDFwK7AtcVlX9AIPVrKpFSc4EbgUeA+4EJg1T+4PNGwJXAT8CTmjm/KMkHwHuaPqdXVU/au7/MfC5JOcA3wQ+1bR/BXgb8ACwHDhxFNcoSZKkCSLP75LQaO0wdUZNPf6C8Z6G1JMeOu/w8Z6CJGkrl2RxVfUNbJ8In4MsSZIkbTLdfIrFuEtyGuvvR76iqs4dj/lIkiRp4nKLxUbo6+ur/v7+8Z6GJEmSNoBbLCRJkqQuGJAlSZKkFgOyJEmS1GJAliRJklp64lMstlRLHlnK9FOuGe9pSBonfpazJE1MriBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWsY0ICc5IcmFYz0+yVFJKklfq+34JN9tbse32j+V5FtJ7k5yZZIXNO2HJlma5K7m9icbOm9JkiT1rp7/HOQkOwMfBG5rte0GnAH0AQUsTnJ1VT0FfKiqnmn6/QXwAeC8ZuhNVfVrm3P+kiRJ2rJ0tYKc5LgktzcrqxclmZRkWZLzkyxOcn2S2UkWJnkwyRGt4dOSLEhyX5IzhqvZtJ+Y5P4kNwJzupjeR4CPAj9ptf0qcF1V/agJxdcBbwFoheMAk+kEaEmSJAnoIiAn2R84GphTVTOB1cCxwE7AwqqaBTwLnAPMBY4Ezm6VmN30nwnMT9I3VM0kU4Gz6ATjucABI8zt1cC0qvrygEN7AT9oPX64aVs77tPAfwIvBz7R6vdLzfaLryZ5xRDnPClJf5L+1cuXDjc9SZIk9aButlgcBswC7ugsujIZeBx4DljQ9FkCrKiqlUmWANNb46+rqicBklwFHAKsGqLmwXRC9xNN/8uB/QabVJJtgI8DJwx2eJC2n64UV9WJzYr1J+gE9U8DdwL7VNWyJG8DvgjMWK9I1cXAxQA7TJ3h6rMkSdIE080WiwCXVNXM5vayqjoTWFlVawPiGmAFQFWtYd3gPTBE1jA1B+s/lJ2BVwILkzwEvBa4unmj3sPAtFbfvYFH15lE1WrgcuDXm8fPVNWy5v5XgO2S7NHlXCRJkjRBdBOQbwCOSrIndN4Al2SfUZxjbjNmMjAPuGWYmrcBhybZPcl2wPyhilbV0qrao6qmV9V0YBFwRFX1A18DfiXJrkl2BX4F+Fo69m3OGeDtwHeaxy9q2kgyu3lunhzFdUqSJGkCGHGLRVXdk+R04NpmW8NK4P2jOMfNwKXAvsBlTYBlsJpVtSjJmcCtwGN0tj1MGsW51s75R0k+AtzRNJ3dtG0DXJLkhXRWsb8F/G7T5yjgd5OsAv4bOKa1Qi5JkqStRMyAG26HqTNq6vEXjPc0JI2Th847fLynIEnaCEkWV1XfwHa/SU+SJElq6YkvCklyGuvvR76iqs4dj/lIkiRp4uqJgNwEYcOwJEmSxlxPBOQt1YF7TaHfPYiSJEkTinuQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSi2/S2whLHlnK9FOuGe9pSNJm4RejSNpauIIsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJahnTgJzkhCQXjuX4JO9Mck+Sbye5bMCxFyZ5pF0jyaeSfCvJ3UmuTPKCpv3DSe5qbv+WZHWS3TZ07pIkSepNPb2CnGQGcCowp6peAfzBgC4fAW4c0PahqnpVVR0EfB/4AEBVfayqZlbVzKbmjVX1o7GcvyRJkrY8XQXkJMclub1ZXb0oyaQky5Kcn2RxkuuTzE6yMMmDSY5oDZ+WZEGS+5KcMVzNpv3EJPcnuRGYM8LUfhv466p6CqCqHm/VnwX8HHBte0BVPdMcDzAZqEHqvgv4bDfPjSRJkiaWEQNykv2Bo+ms0s4EVgPHAjsBC6tqFvAscA4wFzgSOLtVYnbTfyYwP0nfUDWTTAXOohOM5wIHjDC9/YD9ktySZFGStzRz3gb4c+DDQ1zTp4H/BF4OfGLAsR2BtwCfH2LsSUn6k/SvXr50hOlJkiSp13TzVdOHAbOAOzqLrkwGHgeeAxY0fZYAK6pqZZIlwPTW+Ouq6kmAJFcBhwCrhqh5MJ3Q/UTT/3I6IXi4+c8ADgX2Bm5K8krgOOArVfWDpv46qurEZsX6E3SC+qdbh98O3DLU9oqquhi4GGCHqTMGW32WJElSD+smIAe4pKpOXacxObmq1gbENcAKgKpak6Rdd2CIrGFqzhuk/3AeBhZV1Urge0nuoxOYfwl4XZL3AS8Atk+yrKpO+ekkqlY3AfzDrBuQj8HtFZIkSVutbvYg3wAclWRPgCS7JdlnFOeY24yZDMwDbhmm5m3AoUl2T7IdMH+E2l8E3tjU2IPOavODVXVsVb2kqqYDJwOfqapT0rFv0z90Vou/s7ZYkinAG4AvjeL6JEmSNIGMuIJcVfckOR24ttnbuxJ4/yjOcTNwKbAvcFlV9QMMVrOqFiU5E7gVeAy4E5g0TO2vAb+S5B46+5g/vHY7xxACXJLkhc39bwG/2zp+JHBtVf14FNcnSZKkCSTP75LQaO0wdUZNPf6C8Z6GJG0WD513+HhPQZI2qSSLq6pvYHtPfw6yJEmStKl18ya9cZfkNNbfj3xFVZ07HvORJEnSxNUTAbkJwoZhSZIkjbmeCMhbqgP3mkK/e/IkSZImFPcgS5IkSS0GZEmSJKnFgCxJkiS1GJAlSZKkFt+ktxGWPLKU6adcM97TkCRtYfxSFam3uYIsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJahnTgJzkhCQXjuX4JO9Mck+Sbye5rNX+0abt3iR/lSRNe5Kcm+T+5tgHm/aXJ7k1yYokJ2/onCVJktTbevpzkJPMAE4F5lTVU0n2bNp/GZgDHNR0vRl4A7AQOAGYBry8qtasHQP8CPggMG9zzV+SJElbnq5WkJMcl+T2JHcluSjJpCTLkpyfZHGS65PMTrIwyYNJjmgNn5ZkQZL7kpwxXM2m/cRmdfdGOiF3OL8N/HVVPQVQVY837QX8DLA9sAOwHfBfzbHfBc6uqjXtMVX1eFXdAazs5jmRJEnSxDRiQE6yP3A0nVXamcBq4FhgJ2BhVc0CngXOAeYCRwJnt0rMbvrPBOYn6RuqZpKpwFl0gvFc4IARprcfsF+SW5IsSvIWgKq6Ffg68Fhz+1pV3duM+QXg6CT9Sb7arEJ3LclJzdj+1cuXjmaoJEmSekA3WywOA2YBdzTbeCcDjwPPAQuaPkuAFVW1MskSYHpr/HVV9SRAkquAQ4BVQ9Q8mE7ofqLpfzmdEDzc/GcAhwJ7AzcleSWwB7B/0wZwXZLXV9U36Kwo/6Sq+pL8D+D/Aa/r4nkAoKouBi4G2GHqjOp2nCRJknpDNwE5wCVVdeo6jcnJVbU2IK4BVgA0+3rbdQeGyBqm5rxB+g/nYWBRVa0EvpfkPp4PzIuqallT96vAa4FvNGM+34z/AvDpUZxPkiRJE1w3e5BvAI5qvQFutyT7jOIcc5sxk+m8Ae6WYWreBhyaZPck2wHzR6j9ReCNTY096Kw2Pwh8H3hDkm2bOm8A7m2NeVNz/w3A/aO4FkmSJE1wI64gV9U9SU4Hrk2yDZ03sb1/FOe4GbgU2Be4rKr6AQarWVWLkpwJ3Epn7/CdwKRhan8N+JUk99DZx/zhqnoyyZV0QvASOivSC6rqn5sx5wH/mORDwDLgvc18XgT0Ay8E1iT5A+CAqnpmFNcqSZKkHpfnd0lotHaYOqOmHn/BeE9DkrSFeei8w8d7CpK6kGRxVfUNbPeb9CRJkqSWnviikCSnsf5+5Cuq6tzxmI8kSZImrp4IyE0QNgxLkiRpzPVEQN5SHbjXFPrdZyZJkjShuAdZkiRJajEgS5IkSS0GZEmSJKnFgCxJkiS1+Ca9jbDkkaVMP+Wa8Z6GJEkaY375y9bFFWRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSy5gG5CQnJLlwrMYn+XiSu5rb/UmebtpnJrk1ybeT3J3k6NaYm1pjHk3yxab92Kbv3Un+NcmrNnTekiRJ6l09/TnIVfWhtfeT/B7w6ubhcuDdVfXdJC8GFif5WlU9XVWva435PPCl5uH3gDdU1VNJ3gpcDBy8WS5EkiRJW4yuVpCTHJfk9mbV9aIkk5IsS3J+ksVJrk8yO8nCJA8mOaI1fFqSBUnuS3LGcDWb9hOb1eAbgTmjuJZ3AZ8FqKr7q+q7zf1HgceBnx1wTTsDbwK+2PT716p6qjm8CNh7FOeWJEnSBDFiQE6yP3A0MKeqZgKrgWOBnYCFVTULeBY4B5gLHAmc3Soxu+k/E5ifpG+omkmmAmfRCcZzgQO6uYgk+wAvBf5lkGOzge2Bfx9w6Ejghqp6ZpCS7wG+OsS5TkrSn6R/9fKl3UxPkiRJPaSbLRaHAbOAO5IATKazIvscsKDpswRYUVUrkywBprfGX1dVTwIkuQo4BFg1RM2D6YTuJ5r+lwP7dTHHY4Arq2p1u7EJ3JcCx1fVmgFj3gV8cmChJG+kE5APGexEVXUxne0X7DB1RnUxN0mSJPWQbgJygEuq6tR1GpOTq2ptQFwDrACoqjVJ2nUHhsgapua8Qfp34xjg/QNqvRC4Bji9qhYNOLY7nZXtIwe0H0QnNL91baiXJEnS1qWbPcg3AEcl2RMgyW7NloZuzW3GTAbmAbcMU/M24NAkuyfZDpg/UvEkLwN2BW5ttW0PfAH4TFVdMciw+cCXq+onrTEvAa4CfrOq7h/F9UmSJGkCGXEFuaruSXI6cG2SbYCVDFitHcHNdLY57AtcVlX9AIPVrKpFSc6kE3YfA+4EJo1Q/13A51qr2QDvBF4P7J7khKbthKq6q7l/DHDegDp/AuwO/E2z7WNVVfWN4jolSZI0AWTdXKnR2GHqjJp6/AXjPQ1JkjTGHjrv8PGegsZAksWDLYj6TXqSJElSS098UUiS01h/P/IVVXXueMxHkiRJE1dPBOQmCBuGJUmSNOZ6IiBvqQ7cawr97kmSJEmaUNyDLEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWnyT3kZY8shSpp9yzXhPQ5IkqadtaV/E4gqyJEmS1GJAliRJkloMyJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqWVMA3KSE5JcOJbjk7wzyT1Jvp3ksqZtnySLk9zVtP9Oq/8HkjyQpJLs0WpPkr9qjt2d5DUbOm9JkiT1rp7+HOQkM4BTgTlV9VSSPZtDjwG/XFUrkrwA+LckV1fVo8AtwJeBhQPKvRWY0dwOBv62+V9JkiRtRbpaQU5yXJLbmxXZi5JMSrIsyfnNSu31SWYnWZjkwSRHtIZPS7IgyX1JzhiuZtN+YpL7k9wIzBlhar8N/HVVPQVQVY83//tcVa1o+uzQvs6q+mZVPTRIrXcAn6mORcAuSaZ28/xIkiRp4hgxICfZHziazirtTGA1cCywE7CwqmYBzwLnAHOBI4GzWyVmN/1nAvOT9A1VswmkZ9EJxnOBA0aY3n7AfkluSbIoyVta856W5G7gB8D5zerxcPZq+q71cNM28Pk4KUl/kv7Vy5eOUFKSJEm9ppstFocBs4A7kgBMBh4HngMWNH2WACuqamWSJcD01vjrqupJgCRXAYcAq4aoeTCd0P1E0/9yOiF4uPnPAA4F9gZuSvLKqnq6qn4AHJTkxcAXk1xZVf81TK0M0lbrNVRdDFwMsMPUGesdlyRJUm/rZotFgEuqamZze1lVnQmsrKq1AXENsAKgqtawbvAeGCJrmJqD9R/Ow8CXqmplVX0PuI9OYH7+ZJ2V428Dr+ui1rTW472BkVadJUmSNMF0E5BvAI5a+wa4JLsl2WcU55jbjJkMzKPzJrmhat4GHJpk9yTbAfNHqP1F4I1NjT3orDY/mGTv5nwk2ZXOlo37Rqh1NfDu5tMsXgssrarHRnGdkiRJmgBG3GJRVfckOR24Nsk2wErg/aM4x83ApcC+wGVV1Q8wWM2qWpTkTOBWOp9EcScwaZjaXwN+Jck9dPYxf7iqnkwyF/jzJGtXq/+sqpY05/0g8EfAi4C7k3ylqt4LfAV4G/AAsBw4cRTXKEmSpAkiz++S0GjtMHVGTT3+gvGehiRJUk976LzDx+W8SRZXVd/Adr9JT5IkSWrpiS8KSXIa6+9HvqKqzh2P+UiSJGni6omA3ARhw7AkSZLGXE8E5C3VgXtNoX+c9sxIkiRpbLgHWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktRiQJYkSZJaDMiSJElSiwFZkiRJajEgS5IkSS0GZEmSJKnFgCxJkiS1GJAlSZKkFgOyJEmS1GJAliRJkloMyJIkSVKLAVmSJElqMSBLkiRJLQZkSZIkqcWALEmSJLUYkCVJkqQWA7IkSZLUYkCWJEmSWlJV4z2HnpXkWeC+8Z6HfmoP4IfjPQmtw9dky+LrsWXx9diy+HpseTbHa7JPVf3swMZtx/ikE919VdU33pNQR5J+X48ti6/JlsXXY8vi67Fl8fXY8ozna+IWC0mSJKnFgCxJkiS1GJA3zsXjPQGtw9djy+NrsmXx9diy+HpsWXw9tjzj9pr4Jj1JkiSpxRVkSZIkqcWALEmSJLUYkIeQ5C1J7kvyQJJTBjmeJH/VHL87yWu6HavR29DXI8m0JF9Pcm+Sbyf5/c0/+4lnY/59NMcnJflmki9vvllPXBv5/1e7JLkyyXeafye/tHlnPzFt5Gvyoeb/r/4tyWeT/Mzmnf3E08Xr8fIktyZZkeTk0YzV6G3o67FZf6dXlbcBN2AS8O/AzwPbA98CDhjQ523AV4EArwVu63ast836ekwFXtPc3xm439dj/F6P1vE/BC4Dvjze19Prt419PYBLgPc297cHdhnva+r120b+f9ZewPeAyc3jfwJOGO9r6uVbl6/HnsAvAucCJ49mrLfN+npstt/priAPbjbwQFU9WFXPAZ8D3jGgzzuAz1THImCXJFO7HKvR2eDXo6oeq6o7AarqWeBeOr+AtOE25t8HSfYGDgc+uTknPYFt8OuR5IXA64FPAVTVc1X19Gac+0S1Uf9G6HyJ1+Qk2wI7Ao9urolPUCO+HlX1eFXdAawc7ViN2ga/Hpvzd7oBeXB7AT9oPX6Y9V+Aofp0M1ajszGvx08lmQ68Grht009xq7Kxr8cFwB8Ba8ZoflubjXk9fh54Avh0s+Xlk0l2GsvJbiU2+DWpqkeAPwO+DzwGLK2qa8dwrluDjfm97O/0TW+TPKdj/TvdgDy4DNI28PPwhurTzViNzsa8Hp2DyQuAzwN/UFXPbMK5bY02+PVI8mvA41W1eNNPa6u1Mf8+tgVeA/xtVb0a+DHgHsuNtzH/Rnals5r2UuDFwE5JjtvE89vabMzvZX+nb3ob/Zxujt/pBuTBPQxMaz3em/X/xDVUn27GanQ25vUgyXZ0/iH9Y1VdNYbz3FpszOsxBzgiyUN0/qz2piT/MHZT3Sps7P9fPVxVa1dgrqQTmLVxNuY1eTPwvap6oqpWAlcBvzyGc90abMzvZX+nb3ob9Zxurt/pBuTB3QHMSPLSJNsDxwBXD+hzNfDu5p3Ir6XzZ7DHuhyr0dng1yNJ6OyvvLeq/mLzTnvC2uDXo6pOraq9q2p6M+5fqsrVsY2zMa/HfwI/SPKypt9hwD2bbeYT18b8Dvk+8NokOzb//3UYnX2W2nAb83vZ3+mb3gY/p5vzd/q2Y1m8V1XVqiQfAL5G592W/6+qvp3kd5rjfwd8hc67kB8AlgMnDjd2HC5jwtiY14POiuVvAkuS3NW0/a+q+spmvIQJZSNfD21im+D1+D3gH5tfVA/ia7XRNvJ3yG1JrgTuBFYB38SvQN4o3bweSV4E9AMvBNYk+QM6n47wjL/TN62NeT2Ag9hMv9P9qmlJkiSpxS0WkiRJUosBWZIkSWoxIEuSJEktBmRJkiSpxYAsSZIktRiQJUmSpBYDsiRJktTy/wP2RiyL3lBFEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning the best model ---\n",
      "Tuning GradientBoosting with 3 parameters...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 3, 'regressor__n_estimators': 200}\n",
      "\n",
      "Tuned Model Results:\n",
      "  R² Score: 0.4085\n",
      "  RMSE (log scale): 0.2892\n",
      "  MAE (log scale): 0.2283\n",
      "  RMSE (original scale): 9.5194\n",
      "  MAE (original scale): 8.2097\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Training Complete ===\n",
      "\n",
      "--- Predicting on new data ---\n",
      "\n",
      "--- Processing video metadata ---\n",
      "Successfully processed relative time from publish_time\n",
      "Made predictions for 10 videos\n",
      "Prediction statistics: min=27.00, max=193.00, mean=60.81\n",
      "\n",
      "--- Example Predictions ---\n",
      "Video: 283, Actual Likes: 27, Predicted Likes: 27.00\n",
      "Video: 271, Actual Likes: 42, Predicted Likes: 42.00\n",
      "Video: 276, Actual Likes: 193, Predicted Likes: 193.00\n",
      "Video: 282, Actual Likes: 28, Predicted Likes: 28.00\n",
      "Video: 269, Actual Likes: 59, Predicted Likes: 52.36\n",
      "Video: 268, Actual Likes: 81, Predicted Likes: 81.00\n",
      "Video: 288, Actual Likes: 28, Predicted Likes: 28.00\n",
      "Video: 278, Actual Likes: 62, Predicted Likes: 62.00\n",
      "Video: 274, Actual Likes: 57, Predicted Likes: 57.00\n",
      "Video: 289, Actual Likes: 23, Predicted Likes: 37.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# 1. Load the data\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv(\"combined.csv\")\n",
    "    print(f\"Data loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    \n",
    "# 2. Explore the data\n",
    "print(\"\\n--- Data Overview ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- First few rows ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Basic statistics ---\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n--- Missing values ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3. Preprocessing\n",
    "\n",
    "# 3.1 Extract numeric values from embedding column\n",
    "def process_embeddings(df):\n",
    "    \"\"\"Process embeddings column from string to numeric features\"\"\"\n",
    "    print(\"\\n--- Processing embeddings ---\")\n",
    "    \n",
    "    if 'embedding' not in df.columns:\n",
    "        print(\"Warning: 'embedding' column not found in the dataset\")\n",
    "        return df\n",
    "    \n",
    "    # Check if embeddings are already in list form or need parsing from string\n",
    "    if isinstance(df['embedding'].iloc[0], str):\n",
    "        # Convert string of comma-separated values to numpy arrays\n",
    "        print(\"Converting embeddings from string to numeric arrays...\")\n",
    "        try:\n",
    "            # Remove any rows with NaN embeddings\n",
    "            df = df.dropna(subset=['embedding'])\n",
    "            \n",
    "            # Parse the embeddings string to a list of floats\n",
    "            embeddings_list = df['embedding'].apply(lambda x: np.array([float(val) for val in x.split(',')]))\n",
    "            \n",
    "            # Get the dimension of the embeddings\n",
    "            embedding_dim = len(embeddings_list.iloc[0])\n",
    "            print(f\"Embedding dimension: {embedding_dim}\")\n",
    "            \n",
    "            # Create new columns for each embedding dimension\n",
    "            for i in range(embedding_dim):\n",
    "                df[f'embed_{i}'] = embeddings_list.apply(lambda x: x[i] if i < len(x) else np.nan)\n",
    "                \n",
    "            # Drop the original embedding column\n",
    "            df = df.drop('embedding', axis=1)\n",
    "            print(f\"Successfully created {embedding_dim} embedding feature columns\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing embeddings: {e}\")\n",
    "            # If there's an error, drop the embedding column\n",
    "            df = df.drop('embedding', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 3.2 Process text transcriptions\n",
    "def process_transcriptions(df):\n",
    "    \"\"\"Process text transcriptions into features\"\"\"\n",
    "    print(\"\\n--- Processing transcriptions ---\")\n",
    "    \n",
    "    if 'transcription' not in df.columns:\n",
    "        print(\"Warning: 'transcription' column not found in the dataset\")\n",
    "        return df, None\n",
    "    \n",
    "    # Clean transcriptions\n",
    "    df['clean_transcription'] = df['transcription'].fillna('').astype(str).apply(lambda x: x.lower())\n",
    "    \n",
    "    # Extract basic text features\n",
    "    df['transcript_length'] = df['clean_transcription'].apply(len)\n",
    "    df['word_count'] = df['clean_transcription'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    print(\"Generating TF-IDF features from transcriptions...\")\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=100,  # Limit to top 100 features\n",
    "        min_df=2,          # Ignore terms that appear in less than 2 documents\n",
    "        stop_words='english'\n",
    "    )\n",
    "    \n",
    "    # Fit TF-IDF on non-empty transcriptions\n",
    "    non_empty_mask = df['clean_transcription'].str.strip() != ''\n",
    "    if non_empty_mask.sum() > 0:\n",
    "        tfidf_matrix = tfidf.fit_transform(df.loc[non_empty_mask, 'clean_transcription'])\n",
    "        \n",
    "        # Use SVD to reduce dimensionality of TF-IDF features\n",
    "        svd = TruncatedSVD(n_components=min(10, tfidf_matrix.shape[0], tfidf_matrix.shape[1]))\n",
    "        tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "        \n",
    "        # Add SVD components as features\n",
    "        tfidf_cols = [f'tfidf_svd_{i}' for i in range(tfidf_svd.shape[1])]\n",
    "        tfidf_df = pd.DataFrame(tfidf_svd, index=df.loc[non_empty_mask].index, columns=tfidf_cols)\n",
    "        \n",
    "        # Join with original dataframe\n",
    "        df = df.join(tfidf_df)\n",
    "        print(f\"Added {len(tfidf_cols)} TF-IDF SVD features\")\n",
    "        \n",
    "        # Return the fitted TF-IDF vectorizer for later use\n",
    "        return df, (tfidf, svd)\n",
    "    else:\n",
    "        print(\"No valid transcriptions found for TF-IDF processing\")\n",
    "        return df, None\n",
    "\n",
    "# 3.3 Preprocess video metadata\n",
    "def process_metadata(df):\n",
    "    \"\"\"Process video metadata features\"\"\"\n",
    "    print(\"\\n--- Processing video metadata ---\")\n",
    "    \n",
    "    # Handle duration\n",
    "    if 'duration_seconds' in df.columns:\n",
    "        # Create duration bins for potential categorical features\n",
    "        df['duration_bins'] = pd.cut(df['duration_seconds'], \n",
    "                                    bins=[0, 15, 30, 60, 120, float('inf')],\n",
    "                                    labels=['0-15s', '15-30s', '30-60s', '1-2min', '2min+'])\n",
    "    \n",
    "    # Create aspect ratio feature\n",
    "    if 'width' in df.columns and 'height' in df.columns:\n",
    "        df['aspect_ratio'] = df['width'] / df['height']\n",
    "    \n",
    "    # Create resolution category\n",
    "    if 'width' in df.columns and 'height' in df.columns:\n",
    "        def get_resolution_category(row):\n",
    "            if pd.isnull(row['width']) or pd.isnull(row['height']):\n",
    "                return 'Unknown'\n",
    "            pixels = row['width'] * row['height']\n",
    "            if pixels >= 1920*1080:\n",
    "                return 'FullHD+'\n",
    "            elif pixels >= 1280*720:\n",
    "                return 'HD'\n",
    "            elif pixels >= 640*480:\n",
    "                return 'SD'\n",
    "            else:\n",
    "                return 'Low'\n",
    "        \n",
    "        df['resolution_category'] = df.apply(get_resolution_category, axis=1)\n",
    "    \n",
    "    # Process title feature\n",
    "    if 'title' in df.columns:\n",
    "        df['title_length'] = df['title'].fillna('').astype(str).apply(len)\n",
    "        df['title_word_count'] = df['title'].fillna('').astype(str).apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Instead of trying to parse datetime, use the numeric value directly\n",
    "    if 'publish_time' in df.columns:\n",
    "        try:\n",
    "            # Convert to numeric if it's not already\n",
    "            df['publish_numeric'] = pd.to_numeric(df['publish_time'], errors='coerce')\n",
    "            \n",
    "            # Calculate relative time (larger values = newer)\n",
    "            if not df['publish_numeric'].isnull().all():\n",
    "                # Calculate days since oldest publication\n",
    "                min_value = df['publish_numeric'].min()\n",
    "                df['days_since_oldest'] = df['publish_numeric'] - min_value\n",
    "                print(f\"Successfully processed relative time from publish_time\")\n",
    "        except Exception as e:\n",
    "            print(f\"Note: Could not process publish_time as numeric: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 3.4 Prepare final dataset for modeling\n",
    "def prepare_modeling_data(df, target_col='likes'):\n",
    "    \"\"\"Prepare final dataset for modeling\"\"\"\n",
    "    print(\"\\n--- Preparing data for modeling ---\")\n",
    "    \n",
    "    # Check if target column exists\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: Target column '{target_col}' not found in dataset\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Drop rows with missing target values\n",
    "    df_model = df.dropna(subset=[target_col])\n",
    "    print(f\"Rows after dropping missing target values: {df_model.shape[0]}\")\n",
    "    \n",
    "    # Get the target variable\n",
    "    y = df_model[target_col].copy()\n",
    "    print(f\"Target variable statistics: min={y.min()}, max={y.max()}, mean={y.mean():.2f}\")\n",
    "    \n",
    "    # Log transform the target if it's skewed (common for 'likes' counts)\n",
    "    y_log = np.log1p(y)  # log(1+x) to handle zeros\n",
    "    \n",
    "    # Plot target distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(y, bins=30)\n",
    "    plt.title('Original Target Distribution')\n",
    "    plt.xlabel('Likes')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(y_log, bins=30)\n",
    "    plt.title('Log-Transformed Target Distribution')\n",
    "    plt.xlabel('Log(Likes + 1)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Select whether to use original or log-transformed target\n",
    "    # Typically log-transform works better for skewed count data\n",
    "    use_log = True\n",
    "    if use_log:\n",
    "        y_final = y_log\n",
    "        print(\"Using log-transformed target for modeling\")\n",
    "    else:\n",
    "        y_final = y\n",
    "        print(\"Using original target for modeling\")\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    # Exclude the target, ID columns, and any other non-feature columns\n",
    "    exclude_cols = [target_col, 'filename', 'transcription', 'clean_transcription', \n",
    "                    'publish_time', 'embedding']\n",
    "    \n",
    "    # Extract column names by type\n",
    "    numeric_cols = [col for col in df_model.select_dtypes(include=['int64', 'float64']).columns \n",
    "                   if col not in exclude_cols]\n",
    "    \n",
    "    categorical_cols = [col for col in df_model.select_dtypes(include=['object', 'category']).columns \n",
    "                       if col not in exclude_cols]\n",
    "    \n",
    "    # Add any boolean columns to categorical\n",
    "    bool_cols = [col for col in df_model.select_dtypes(include=['bool']).columns \n",
    "                if col not in exclude_cols]\n",
    "    categorical_cols.extend(bool_cols)\n",
    "    \n",
    "    print(f\"Selected {len(numeric_cols)} numeric features and {len(categorical_cols)} categorical features\")\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = df_model[numeric_cols + categorical_cols].copy()\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_final, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Create feature list dictionaries\n",
    "    features = {\n",
    "        'numeric': numeric_cols,\n",
    "        'categorical': categorical_cols\n",
    "    }\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test), features, use_log\n",
    "\n",
    "# 4. Modeling\n",
    "def build_model(X_train, X_test, y_train, y_test, features, use_log=True):\n",
    "    \"\"\"Build and evaluate prediction models\"\"\"\n",
    "    print(\"\\n--- Building prediction models ---\")\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, features['numeric']),\n",
    "            ('cat', categorical_transformer, features['categorical'])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Define models to try\n",
    "    models = {\n",
    "        'RandomForest': RandomForestRegressor(random_state=42),\n",
    "        'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "        'ElasticNet': ElasticNet(random_state=42),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Add XGBoost if available\n",
    "        models['XGBoost'] = XGBRegressor.XGBRegressor(random_state=42)\n",
    "    except:\n",
    "        print(\"XGBoost not available, skipping\")\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Create pipeline with preprocessing\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Fit the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # If we used log transform, convert predictions back to original scale\n",
    "        if use_log:\n",
    "            y_pred_original = np.expm1(y_pred)\n",
    "            y_test_original = np.expm1(y_test)\n",
    "        else:\n",
    "            y_pred_original = y_pred\n",
    "            y_test_original = y_test\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Calculate metrics on original scale\n",
    "        rmse_original = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "        mae_original = mean_absolute_error(y_test_original, y_pred_original)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': pipeline,\n",
    "            'r2': r2,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'rmse_original': rmse_original,\n",
    "            'mae_original': mae_original\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} Results:\")\n",
    "        print(f\"  R² Score: {r2:.4f}\")\n",
    "        print(f\"  RMSE (log scale): {rmse:.4f}\")\n",
    "        print(f\"  MAE (log scale): {mae:.4f}\")\n",
    "        print(f\"  RMSE (original scale): {rmse_original:.4f}\")\n",
    "        print(f\"  MAE (original scale): {mae_original:.4f}\")\n",
    "    \n",
    "    # Find the best model based on R²\n",
    "    best_model_name = max(results, key=lambda x: results[x]['r2'])\n",
    "    print(f\"\\nBest model: {best_model_name} with R² = {results[best_model_name]['r2']:.4f}\")\n",
    "    \n",
    "    # Plot actual vs predicted values for the best model\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    best_model = results[best_model_name]['model']\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if use_log:\n",
    "        plt.scatter(np.expm1(y_test), np.expm1(y_pred), alpha=0.5)\n",
    "        plt.title(f'Actual vs Predicted Likes ({best_model_name})')\n",
    "        plt.xlabel('Actual Likes')\n",
    "        plt.ylabel('Predicted Likes')\n",
    "    else:\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.title(f'Actual vs Predicted Likes ({best_model_name})')\n",
    "        plt.xlabel('Actual Likes')\n",
    "        plt.ylabel('Predicted Likes')\n",
    "    \n",
    "    # Add a perfect prediction line\n",
    "    max_val = max(plt.xlim()[1], plt.ylim()[1])\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If the best model is RandomForest or GradientBoosting, show feature importance\n",
    "    if best_model_name in ['RandomForest', 'GradientBoosting', 'XGBoost']:\n",
    "        feature_names = get_feature_names(best_model.named_steps['preprocessor'])\n",
    "        \n",
    "        if hasattr(best_model.named_steps['regressor'], 'feature_importances_'):\n",
    "            importances = best_model.named_steps['regressor'].feature_importances_\n",
    "            indices = np.argsort(importances)[-20:]  # Top 20 features\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.title(f'Top 20 Feature Importances ({best_model_name})')\n",
    "            plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "            plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from column transformer\"\"\"\n",
    "    output_features = []\n",
    "    \n",
    "    for name, pipe, features in column_transformer.transformers_:\n",
    "        if name == 'drop' or pipe == 'drop':\n",
    "            continue\n",
    "            \n",
    "        if hasattr(pipe, 'get_feature_names_out'):\n",
    "            if isinstance(features, slice):\n",
    "                output_features.extend(pipe.get_feature_names_out())\n",
    "            else:\n",
    "                output_features.extend(pipe.get_feature_names_out(input_features=features))\n",
    "        else:\n",
    "            # For transformers without get_feature_names_out, try to reconstruct names\n",
    "            for f in features:\n",
    "                output_features.append(f\"{name}__{f}\")\n",
    "    \n",
    "    return output_features\n",
    "\n",
    "# 5. Model tuning\n",
    "def tune_best_model(X_train, X_test, y_train, y_test, features, best_model_name, use_log=True):\n",
    "    \"\"\"Tune the best model with hyperparameter optimization\"\"\"\n",
    "    print(\"\\n--- Tuning the best model ---\")\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, features['numeric']),\n",
    "            ('cat', categorical_transformer, features['categorical'])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Define parameter grids for different models\n",
    "    param_grids = {\n",
    "        'RandomForest': {\n",
    "            'regressor__n_estimators': [50, 100, 200],\n",
    "            'regressor__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'regressor__n_estimators': [50, 100, 200],\n",
    "            'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'regressor__max_depth': [3, 5, 7]\n",
    "        },\n",
    "        'ElasticNet': {\n",
    "            'regressor__alpha': [0.001, 0.01, 0.1, 1, 10],\n",
    "            'regressor__l1_ratio': [0.1, 0.5, 0.7, 0.9]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'regressor__n_estimators': [50, 100, 200],\n",
    "            'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'regressor__max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Select model class based on name\n",
    "    if best_model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    elif best_model_name == 'GradientBoosting':\n",
    "        model = GradientBoostingRegressor(random_state=42)\n",
    "    elif best_model_name == 'ElasticNet':\n",
    "        model = ElasticNet(random_state=42)\n",
    "    elif best_model_name == 'XGBoost':\n",
    "        model = XGBRegressor.XGBRegressor(random_state=42)\n",
    "    else:\n",
    "        print(f\"Unknown model: {best_model_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Create grid search\n",
    "    param_grid = param_grids[best_model_name]\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    print(f\"Tuning {best_model_name} with {len(param_grid)} parameters...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Evaluate best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # If we used log transform, convert predictions back to original scale\n",
    "    if use_log:\n",
    "        y_pred_original = np.expm1(y_pred)\n",
    "        y_test_original = np.expm1(y_test)\n",
    "    else:\n",
    "        y_pred_original = y_pred\n",
    "        y_test_original = y_test\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Calculate metrics on original scale\n",
    "    rmse_original = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "    mae_original = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    \n",
    "    print(\"\\nTuned Model Results:\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(f\"  RMSE (log scale): {rmse:.4f}\")\n",
    "    print(f\"  MAE (log scale): {mae:.4f}\")\n",
    "    print(f\"  RMSE (original scale): {rmse_original:.4f}\")\n",
    "    print(f\"  MAE (original scale): {mae_original:.4f}\")\n",
    "    \n",
    "    # Plot actual vs predicted values for the tuned model\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if use_log:\n",
    "        plt.scatter(np.expm1(y_test), np.expm1(y_pred), alpha=0.5)\n",
    "        plt.title(f'Actual vs Predicted Likes (Tuned {best_model_name})')\n",
    "        plt.xlabel('Actual Likes')\n",
    "        plt.ylabel('Predicted Likes')\n",
    "    else:\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.title(f'Actual vs Predicted Likes (Tuned {best_model_name})')\n",
    "        plt.xlabel('Actual Likes')\n",
    "        plt.ylabel('Predicted Likes')\n",
    "    \n",
    "    # Add a perfect prediction line\n",
    "    max_val = max(plt.xlim()[1], plt.ylim()[1])\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# 6. Make predictions on new data\n",
    "def predict_on_new_data(model, new_data, features, tfidf_pipeline=None, use_log=True):\n",
    "    \"\"\"Make predictions on new data\"\"\"\n",
    "    print(\"\\n--- Predicting on new data ---\")\n",
    "    \n",
    "    # Process the new data the same way as training data\n",
    "    new_data_processed = new_data.copy()\n",
    "    \n",
    "    # Process embeddings if present\n",
    "    if 'embedding' in new_data.columns:\n",
    "        new_data_processed = process_embeddings(new_data_processed)\n",
    "    \n",
    "    # Process transcriptions if present and TF-IDF pipeline is provided\n",
    "    if 'transcription' in new_data.columns and tfidf_pipeline is not None:\n",
    "        tfidf, svd = tfidf_pipeline\n",
    "        \n",
    "        # Clean transcriptions\n",
    "        new_data_processed['clean_transcription'] = new_data_processed['transcription'].fillna('').astype(str).apply(lambda x: x.lower())\n",
    "        \n",
    "        # Extract basic text features\n",
    "        new_data_processed['transcript_length'] = new_data_processed['clean_transcription'].apply(len)\n",
    "        new_data_processed['word_count'] = new_data_processed['clean_transcription'].apply(lambda x: len(x.split()))\n",
    "        \n",
    "        # Transform with pre-fitted TF-IDF and SVD\n",
    "        non_empty_mask = new_data_processed['clean_transcription'].str.strip() != ''\n",
    "        if non_empty_mask.sum() > 0:\n",
    "            tfidf_matrix = tfidf.transform(new_data_processed.loc[non_empty_mask, 'clean_transcription'])\n",
    "            tfidf_svd = svd.transform(tfidf_matrix)\n",
    "            \n",
    "            # Add SVD components as features\n",
    "            tfidf_cols = [f'tfidf_svd_{i}' for i in range(tfidf_svd.shape[1])]\n",
    "            \n",
    "            # Check if columns already exist, and handle by removing them first\n",
    "            existing_tfidf_cols = [col for col in tfidf_cols if col in new_data_processed.columns]\n",
    "            if existing_tfidf_cols:\n",
    "                new_data_processed = new_data_processed.drop(columns=existing_tfidf_cols)\n",
    "            \n",
    "            # Create DataFrame with TF-IDF features\n",
    "            tfidf_df = pd.DataFrame(tfidf_svd, index=new_data_processed.loc[non_empty_mask].index, columns=tfidf_cols)\n",
    "            \n",
    "            # Use pandas concat instead of join to avoid column name conflicts\n",
    "            new_data_processed = pd.concat([new_data_processed, tfidf_df], axis=1)\n",
    "    \n",
    "    # Process metadata\n",
    "    new_data_processed = process_metadata(new_data_processed)\n",
    "    \n",
    "    # Select only features that were used in training\n",
    "    # Ensure all required features exist in the data\n",
    "    missing_features = [col for col in features['numeric'] + features['categorical'] if col not in new_data_processed.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features in prediction data: {missing_features}\")\n",
    "        # Add missing features with NaN values\n",
    "        for col in missing_features:\n",
    "            new_data_processed[col] = np.nan\n",
    "    \n",
    "    X_new = new_data_processed[features['numeric'] + features['categorical']].copy()\n",
    "    \n",
    "    # Make predictions\n",
    "    try:\n",
    "        y_pred = model.predict(X_new)\n",
    "        \n",
    "        # If we used log transform, convert predictions back to original scale\n",
    "        if use_log:\n",
    "            y_pred_original = np.expm1(y_pred)\n",
    "        else:\n",
    "            y_pred_original = y_pred\n",
    "        \n",
    "        # Add predictions to the original data\n",
    "        new_data['predicted_likes'] = y_pred_original\n",
    "        \n",
    "        print(f\"Made predictions for {len(new_data)} videos\")\n",
    "        print(f\"Prediction statistics: min={new_data['predicted_likes'].min():.2f}, max={new_data['predicted_likes'].max():.2f}, mean={new_data['predicted_likes'].mean():.2f}\")\n",
    "        \n",
    "        return new_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error making predictions: {e}\")\n",
    "        return None\n",
    "    \n",
    "# 7. Main execution\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"=== Video Likes Prediction Model ===\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(\"combined.csv\")\n",
    "    \n",
    "    # Process data\n",
    "    df = process_embeddings(df)\n",
    "    df, tfidf_pipeline = process_transcriptions(df)\n",
    "    df = process_metadata(df)\n",
    "    \n",
    "    # Prepare for modeling\n",
    "    (X_train, X_test, y_train, y_test), features, use_log = prepare_modeling_data(df)\n",
    "    \n",
    "    # Build models\n",
    "    results = build_model(X_train, X_test, y_train, y_test, features, use_log)\n",
    "    \n",
    "    # Find the best model\n",
    "    best_model_name = max(results, key=lambda x: results[x]['r2'])\n",
    "    \n",
    "    # Tune the best model\n",
    "    tuned_model = tune_best_model(X_train, X_test, y_train, y_test, features, best_model_name, use_log)\n",
    "    \n",
    "    # Save the tuned model (for demonstration)\n",
    "    # We'd use joblib.dump(tuned_model, 'video_likes_model.joblib') in a real scenario\n",
    "    \n",
    "    print(\"\\n=== Model Training Complete ===\")\n",
    "    \n",
    "    # Example: Predict on new data (here we're using our test set as an example)\n",
    "    # In a real scenario, you would load new data for prediction\n",
    "    new_data_example = df.sample(min(10, len(df)))\n",
    "    predictions = predict_on_new_data(tuned_model, new_data_example, features, tfidf_pipeline, use_log)\n",
    "    \n",
    "    if predictions is not None:\n",
    "        print(\"\\n--- Example Predictions ---\")\n",
    "        for _, row in predictions.iterrows():\n",
    "            if 'likes' in row:\n",
    "                print(f\"Video: {row['filename']}, Actual Likes: {row['likes']}, Predicted Likes: {row['predicted_likes']:.2f}\")\n",
    "            else:\n",
    "                print(f\"Video: {row['filename']}, Predicted Likes: {row['predicted_likes']:.2f}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b0120ee620a47978946e3256b7b1a32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b9791b6f59b454f8d587bf35441a4f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d12f1f605bc4fb697a628c4ffde836e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "161e89d5e12940b8b2578f982f938167": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21f19fc25039400baa9a591b038e4695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2796f08190dd4f1bb57a5514e30165be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aee8f66b1514a829c5a4848c8e9ed93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b3f86b7f61441d69afe6227c4370740",
       "IPY_MODEL_6d97656ec6ef4605ac2b1d3dc8b2efaa",
       "IPY_MODEL_6b7b2cdf8c354eaeaeca3719bde42a55"
      ],
      "layout": "IPY_MODEL_e043131b7a8c43a2999649dedf859c73"
     }
    },
    "2fabf13660a44f8fa186c8cd01b97663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b0120ee620a47978946e3256b7b1a32",
      "placeholder": "​",
      "style": "IPY_MODEL_cbcf3f0dbe434f1ebd6d41f7a7010df5",
      "value": " 566M/4.95G [00:09&lt;01:07, 65.2MB/s]"
     }
    },
    "34b9f0efa8184ab78f307019dcbe6c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39fc286c0ee444efac547d4715fab3e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ac4618bd2f1482baba2e5dbac28be9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afbf5643731c4372a0e5d0f66687be63",
      "placeholder": "​",
      "style": "IPY_MODEL_5eaf7c6a4b524f438093b07d2855dff0",
      "value": "model-00001-of-00003.safetensors: 100%"
     }
    },
    "419fa0b3fd494c5391444d964b84f0ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42292df633dd4c7cb00e03fcfe0f0623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53eb04f5383c4369a7eb67d43045d84c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "562c55cfaacf4ba1a12bc8faad7a8d69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5653c8e6fc484d31a9c9e920106d8f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53eb04f5383c4369a7eb67d43045d84c",
      "placeholder": "​",
      "style": "IPY_MODEL_68f63f216c4148908ff01ec951f32ac6",
      "value": "model-00002-of-00003.safetensors:  11%"
     }
    },
    "5eaf7c6a4b524f438093b07d2855dff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62f57902c5a34c8ba9df3a17ec04088a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "649644b1e40743beaadd4b118c5e0da2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68f63f216c4148908ff01ec951f32ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b7b2cdf8c354eaeaeca3719bde42a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b9791b6f59b454f8d587bf35441a4f3",
      "placeholder": "​",
      "style": "IPY_MODEL_f2bb0affafb948c4aa9e05653f7b9376",
      "value": " 1/3 [01:19&lt;02:39, 79.78s/it]"
     }
    },
    "6bec2f0f8aaa46739e85f7aebcda5ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_562c55cfaacf4ba1a12bc8faad7a8d69",
      "placeholder": "​",
      "style": "IPY_MODEL_f314d6e524a248dfae72e7512f7dbebc",
      "value": " 4.98G/4.98G [01:19&lt;00:00, 71.9MB/s]"
     }
    },
    "6d97656ec6ef4605ac2b1d3dc8b2efaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ae457232e6499ab4fae65d0efb0666",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21f19fc25039400baa9a591b038e4695",
      "value": 1
     }
    },
    "78b0f5ae4d2b4284b530a5d8df3a792a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2796f08190dd4f1bb57a5514e30165be",
      "max": 4947392504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1f3f90c894245268c4668f747fa8cd3",
      "value": 566231040
     }
    },
    "7aeb04b600c34772b1c4022cf21ffcfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e620713c095d4a1996bc37d20579f7d5",
      "max": 4979992712,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d78a394e68f043f98f96976a288214eb",
      "value": 4979992712
     }
    },
    "82ae457232e6499ab4fae65d0efb0666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87aac3331be4455ba33267e3a2d7d435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df3e30c9ff7f4fdab6f06f954b115165",
       "IPY_MODEL_c9b9903af3f24a9bb06cc89306308119",
       "IPY_MODEL_c5cc0dd3cdae4c3f9656befac5464830"
      ],
      "layout": "IPY_MODEL_9634df0b9a734cbc9dad40f8d0d95cad"
     }
    },
    "8b3f86b7f61441d69afe6227c4370740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c21f27bb523e49c0a5784d80b8c51600",
      "placeholder": "​",
      "style": "IPY_MODEL_f43ec6daa1a84b18b65084d6f0cee304",
      "value": "Downloading shards:  33%"
     }
    },
    "9634df0b9a734cbc9dad40f8d0d95cad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96ee96d16a754737bc548ca957f057d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ac4618bd2f1482baba2e5dbac28be9a",
       "IPY_MODEL_7aeb04b600c34772b1c4022cf21ffcfb",
       "IPY_MODEL_6bec2f0f8aaa46739e85f7aebcda5ba4"
      ],
      "layout": "IPY_MODEL_cd01c3096121408588c4d0af726a68b7"
     }
    },
    "a4654f6aac164f379911b35b818b3a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a67a5fe937204b5b8f5bd01e7cdb2256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f992c760007c4a64848e8c38e374c897",
      "placeholder": "​",
      "style": "IPY_MODEL_b99d04e19fbe43ac94b8aaa3087b6a39",
      "value": " 112k/112k [00:00&lt;00:00, 1.58MB/s]"
     }
    },
    "afbf5643731c4372a0e5d0f66687be63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1f3f90c894245268c4668f747fa8cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b99d04e19fbe43ac94b8aaa3087b6a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c21f27bb523e49c0a5784d80b8c51600": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5cc0dd3cdae4c3f9656befac5464830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d12f1f605bc4fb697a628c4ffde836e",
      "placeholder": "​",
      "style": "IPY_MODEL_34b9f0efa8184ab78f307019dcbe6c65",
      "value": " 998/998 [00:00&lt;00:00, 91.9kB/s]"
     }
    },
    "c9b9903af3f24a9bb06cc89306308119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4654f6aac164f379911b35b818b3a8a",
      "max": 998,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39fc286c0ee444efac547d4715fab3e9",
      "value": 998
     }
    },
    "cbcf3f0dbe434f1ebd6d41f7a7010df5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd01c3096121408588c4d0af726a68b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1cf7743138143be841ea971c13705b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5653c8e6fc484d31a9c9e920106d8f63",
       "IPY_MODEL_78b0f5ae4d2b4284b530a5d8df3a792a",
       "IPY_MODEL_2fabf13660a44f8fa186c8cd01b97663"
      ],
      "layout": "IPY_MODEL_42292df633dd4c7cb00e03fcfe0f0623"
     }
    },
    "d6de83563fdf44fe92c75b18f46f44e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d78a394e68f043f98f96976a288214eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df3e30c9ff7f4fdab6f06f954b115165": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_419fa0b3fd494c5391444d964b84f0ba",
      "placeholder": "​",
      "style": "IPY_MODEL_d6de83563fdf44fe92c75b18f46f44e3",
      "value": "config.json: 100%"
     }
    },
    "e043131b7a8c43a2999649dedf859c73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1dd6d5e784344beb94c047331db6ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4ead2c5b9b745e6bb76b127f50f5953",
       "IPY_MODEL_ecc8b09352e04118ae193eb28af78879",
       "IPY_MODEL_a67a5fe937204b5b8f5bd01e7cdb2256"
      ],
      "layout": "IPY_MODEL_e687daddd2f0487ba92878a7281e5ba9"
     }
    },
    "e4ead2c5b9b745e6bb76b127f50f5953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fadbc59282cf4fac9e591abff4cba4e9",
      "placeholder": "​",
      "style": "IPY_MODEL_62f57902c5a34c8ba9df3a17ec04088a",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "e620713c095d4a1996bc37d20579f7d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e687daddd2f0487ba92878a7281e5ba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecc8b09352e04118ae193eb28af78879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_649644b1e40743beaadd4b118c5e0da2",
      "max": 111923,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_161e89d5e12940b8b2578f982f938167",
      "value": 111923
     }
    },
    "f2bb0affafb948c4aa9e05653f7b9376": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f314d6e524a248dfae72e7512f7dbebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f43ec6daa1a84b18b65084d6f0cee304": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f992c760007c4a64848e8c38e374c897": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fadbc59282cf4fac9e591abff4cba4e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
